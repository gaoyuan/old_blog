<?xml version="1.0"?>
<rss version="2.0">
  <channel>
    <title>Desiderata</title>
    <link>http://blog.charlesgao.com/</link>
    <pubDate>2015-09-02 14:42:10 +0800</pubDate>
    <item>
      <title>Bayesian Logistic Regression</title>
      <link>http://blog.charlesgao.com//2015/05/23/bayesian-logistic-regression.html</link>
      <pubDate>2015-05-23</pubDate>
      <description>&lt;!DOCTYPE html&gt;
&lt;html lang="en"&gt;
&lt;head&gt;
  &lt;meta charset="utf-8"&gt;
  &lt;title&gt;Bayesian Logistic Regression&lt;/title&gt;
  &lt;link href="/assets/charlesgao/stylesheets/style.css?0.7670297939709138" type="text/css" rel="stylesheet" media="all"&gt;
&lt;link href="/assets/charlesgao/widgets/google_prettify/stylesheets/twitter-bootstrap.css?0.9373519569618196" type="text/css" rel="stylesheet" media="all"&gt;


  &lt;script&gt;
  var _gaq=[['_setAccount','UA-33798309-1'],['_trackPageview']];
  (function(d,t){var g=d.createElement(t),s=d.getElementsByTagName(t)[0];
  g.src=('https:'==location.protocol?'//ssl':'//www')+'.google-analytics.com/ga.js';
  s.parentNode.insertBefore(g,s)}(document,'script'));
&lt;/script&gt;
    &lt;script type='text/x-mathjax-config'&gt;
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [['$','$'], ['\\(','\\)']],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        }
    });
    MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i &lt; all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
    });
    &lt;/script&gt;
    &lt;script type='text/javascript' src='http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'&gt;&lt;/script&gt;
&lt;/head&gt;

&lt;body onLoad="init();"&gt;

    &lt;div class="blog-title"&gt;
      &lt;h1&gt;&lt;a href="/"&gt;Desiderata&lt;/a&gt;&lt;/h1&gt;
      &lt;h3&gt;Yet another blog of Yuan Gao.&lt;/h3&gt;
    &lt;/div&gt;

    &lt;div class="content"&gt;
      &lt;div class="post"&gt;
  &lt;div class="title"&gt;&lt;a href=""&gt;Bayesian Logistic Regression&lt;/a&gt; &lt;span class="date"&gt;2015-05-23&lt;/span&gt;&lt;/h3&gt;&lt;/div&gt;
  &lt;div&gt;
  &lt;p&gt;The Bayesian approach to machine learning replaces the sauce of optimization by that of probability. Instead of maximizing the likelihood, it introduces prior to the parameters and calculates the posterior distribution of the parameters after seeing all the data using Bayes&amp;#39; rule (of course!). The posterior distribution captures our beliefs about the parameters, and it is definitely more informative than a single optimal set of parameters learned from maximizing the likelihood. However the extra information comes at a price, since inferring about the posterior is often computationally expansive. For carefully chosen priors and likelihood (conjugacy), it is possible to get analytical solution for the posterior, but unfortunately in reality this is rarely the case, even for the simple logistic regression model.&lt;/p&gt;

&lt;p&gt;The logistic regression model is widely used in classification. For simplicity and visualization purposes we will study a simple 2d classification problem, where we assume that the data points can be separated by a line passing through the origin. This is of course a bad assumption in general, but who cares -- no model is perfect anyways.&lt;/p&gt;

&lt;p&gt;For logistic regression, we take the probability of a data point $(x_i, y_i) \in \mathbb{R}^2$ belonging to class $z_i \in \{0, 1\}$ as
\begin{equation}
P(Z = 0 | X = (x_i, y_i), A = a, B = b) = \frac{1}{1 + exp(-ax_i - by_i)},
\end{equation}
where $A$, $B$ are the parameters in our model. In a Bayesian&amp;#39;s eyes, they are not cold-blooded reptiles (a number) but warm-blooded mammals (random variables). Wait, I love mammals, but what is our prior belief about them, before seeing any training examples? While, I don&amp;#39;t have any, my intuition is just that any line is equally likely to separate the positive and negative training examples. How does that translates to the priors of $A$ and $B$?&lt;/p&gt;

&lt;p&gt;For that, let&amp;#39;s look at the probability of points belonging to the opposite class
\begin{equation}
P(Z = 1 | X = (x_i, y_i), A = a, B = b) = 1 - P(Z = 0 | X = (x_i, y_i), A = a, B = b) = \frac{exp(-ax_i - by_i)}{1 + exp(-ax_i - by_i)}.
\end{equation}
If the point $(x_i, y_i)$ happens to lie on the decision boundary, we must have
\begin{equation}
P(Z = 1 | X = (x_i, y_i), A = a, B = b) = P(Z = 0 | X = (x_i, y_i), A = a, B = b).
\end{equation}
This corresponds to the condition
\begin{equation}
ax_i + by_i = 0.
\end{equation}
If a point $(x_i, y_i)$ lies on the decision boundary, it must satisfy the above equation. In other words, the decision boundary is defined by $ax + by = 0$, a line passing through the origin! Great, now the model perfectly resonates with our initial assumptions. The last dessert to make is to define the priors for $A$ and $B$ such that it reflects our belief that any line is equally likely. This is in fact very tricky. We have to formalize the term &lt;em&gt;equally likely&lt;/em&gt;. One way to formalize it is to say that the slope of the line is uniformly distributed in $\mathbb{R}$. But what is an uniform distribution in $\mathbb{R}$? The answer is that there is &lt;strong&gt;no&lt;/strong&gt; uniform distribution in $\mathbb{R}$! This weired object is opposite to the $\delta$-distribution, but unfortunately is not well-defined in any mathematical framework (distribution theory, measure theory) to the best of my knowledge. It can be seen as a limit of an uniform distribution in $[-M, M]$ as $M \rightarrow \infty$, or as the stationary distribution of a Brownian motion as $t \rightarrow \infty$. OK, I feel that I&amp;#39;m ranting on it too much. Let&amp;#39;s try to formalize it in another way. We can say that the angle formed by the line and the positive x-axis is uniformly distributed in $[-\pi/2, \pi/2]$. This is well defined, and the angle is related to the slope through a nonlinear map $\Theta \mapsto \tan(\Theta)$. What is corresponding distribution of the slope you might ask? It is the Cauchy distribution. Uniformity in angle is essentially different from uniformity in slope, a phenomena similar to Bertrand paradox. Anyway, we can now at least realize our second formalization by sampling $\Theta$ uniformly in $[-\pi/2, \pi/2]$, and take $A = \sin\Theta$ and $B = \cos\Theta$. It turns out there is a way to generate Cauchy distribution even when $A$ and $B$ are independent. If $A$ and $B$ are independent standard normal distributions, their ratio $A/B$ (or equivalently the actual slope $-A/B$) is Cauchy distributed. Here let&amp;#39;s adopt this approach, because the Gaussian (normal) prior is extremely popular and we&amp;#39;ve proved that it satisfies our prior belief in this case.&lt;/p&gt;

&lt;p&gt;Let&amp;#39;s first draw some samples from the prior and see how they look like. Below is a plot of 50 random lines drawn from our prior:&lt;/p&gt;

&lt;p&gt;&lt;img src="/assets/media/fig8.png" /&gt;&lt;/p&gt;

&lt;p&gt;Seem pretty uniform, aren&amp;#39;t they? Here is the density of the joint probability density of $(A, B)$:&lt;/p&gt;

&lt;p&gt;&lt;img src="/assets/media/fig9.png" /&gt;&lt;/p&gt;

&lt;p&gt;Now let&amp;#39;s make some toy training examples :)&lt;/p&gt;

&lt;p&gt;&lt;img src="/assets/media/fig10.png" /&gt;&lt;/p&gt;

&lt;p&gt;Given the set of training examples $\{(x_1, y_1, z_1), (x_2, y_2, z_2), \ldots, (x_n, y_n, z_n)\}$, the likelihood is
\begin{equation}
P(Z = \mathbf{z} | X = (\mathbf{x}, \mathbf{y}), A = a, B = b) = \prod_{i = 1}^n \frac{exp(z_i(-ax_i - by_i))}{1 + exp(-ax_i - by_i)}.
\end{equation}
The posterior distribution is then proportional to the prior times the likelihood:
\begin{equation}
P(A, B|X, Z) \propto P(A)P(B)P(Z|X, A, B).
\end{equation}
Unfortunately there is no analytical solution for the posterior, because $P(A)$ and $P(B)$ are Gaussians but the likelihood $P(Z|X, A, B)$ is a product of logistic functions. In order to get a feeling what the posterior looks like, let&amp;#39;s calculate $P(A)P(B)P(Z|X, A, B)$ for a square grid of $(a, b)$ ranging from -3 to 3, with a step size of 0.1:&lt;/p&gt;

&lt;p&gt;&lt;img src="/assets/media/fig11.png" /&gt;&lt;/p&gt;

&lt;p&gt;We can see that after seeing the training examples, our beliefs about $A$ and $B$ shifted. The approximate mode, or the point that has the maximum probability in the grid, is (1.6, 0.4). The corresponding (unnormalized) posterior probability is 0.005.&lt;/p&gt;

&lt;p&gt;Now let&amp;#39;s try to sample some lines from the posterior. To do this I first generate a random number $r$ between $0$ and $1$. Then I sample a point $(a, b)$ uniformly in the square $[-3, 3] \times [-3, 3]$, and calculates $P(A=a)P(B=b)P(Z|X, A=a, B=b)$. If this unnormalized posterior probability is less than $0.005r$, I will keep it. Otherwise I will reject it. This idea is called rejection sampling, and one can show that the sampled points will follow the posterior distribution. The fact that I&amp;#39;m only sampling $(a, b)$ in a small square does not affect the result so much, because I can tell that most densities are included in this region from the previous plot. Below is a plot of running rejection sampling for 1000 iterations. The grey lines are rejected lines and black lines are approved samples. The thick red line corresponds to the mode.&lt;/p&gt;

&lt;p&gt;&lt;img src="/assets/media/fig12.png" /&gt;&lt;/p&gt;

&lt;p&gt;The number of training examples influences the variance of the posterior. Here we have 7 positive and 7 negative examples, and we can see that we are already pretty confident about our beliefs. If we only have 6 training instances instead (less evidence), the picture would look like this:&lt;/p&gt;

&lt;p&gt;&lt;img src="/assets/media/fig13.png" /&gt;&lt;/p&gt;

&lt;p&gt;Finally, to make predictions, given a test data point $X^*$, the Bayesian approach is to average across all possible parameters:
\begin{equation}
P(Z^*|X^*, Z, X) = \int P(Z^*|X^*, A, B)P(A, B|X, Z)dAdB.
\end{equation}
Again the integral is a monster, but we can approximate it by sampling. For example, I can take the grid points in the $[-3, 3] \times [-3, 3]$ square as a rough approximation to the posterior, and make predictions by summing over all those points. For a test point $(-1, 0)$, this will return us a probability of 0.1597, so we are pretty confident that it belongs to the red class. For a test point of $(1, 0)$, the probability is 0.8403, safe to say it is green.&lt;/p&gt;

&lt;p&gt;A quick exercise: what will the learned model predict for the point $(0, 0)$? Does the choice of prior and training examples influence the prediction for $(0, 0)$? Why?&lt;/p&gt;

&lt;p&gt;Code used in this study:&lt;/p&gt;

&lt;pre&gt;&lt;code class="matlab"&gt;% randn(&amp;#39;seed&amp;#39;, 0);
% rand(&amp;#39;seed&amp;#39;, 0);

% prior
mu = 0;
sigma = 1;

% draw samples from prior
box = 3;
x = -box:0.1:box;
for i = 1:50
    a = normrnd(mu, sigma);
    b = normrnd(mu, sigma);
    plot(x, -a/b * x, &amp;#39;color&amp;#39;, [0.8 0.8 0.8]);
    hold on
end
axis([-box box -box box]);

% draw prior density
[X, Y] = meshgrid(normpdf(x, mu, sigma), normpdf(x, mu, sigma));
pcolor(X.*Y);
shading(&amp;#39;interp&amp;#39;);
set(gca, &amp;#39;XTick&amp;#39;, [], &amp;#39;YTick&amp;#39;, []);

% observed data
pos = [1, 1; 2, 0; 2, 1; 0, 2; 1, 2; 0, 3; 2, -1];
neg = [-1, 1; -1, 0; -1, -1; -1, 2; -2, 0; -2, 1; -2, 2];
scatter(pos(:, 1), pos(:, 2), &amp;#39;o&amp;#39;);
scatter(neg(:, 1), neg(:, 2), &amp;#39;x&amp;#39;);

% draw posterior density
prob_mat = zeros(length(x));
for j = 1:length(x)
    for k = 1:length(x)
        a = x(j);
        b = x(k);
        prob = normpdf(a, mu, sigma) * normpdf(b, mu, sigma);
        for i = 1:size(pos, 1)
            prob = prob * 1/(1 + exp(-a * pos(i, 1) - b * pos(i, 2)));
        end
        for i = 1:size(neg, 1)
            prob = prob * (1 - 1/(1 + exp(-a * neg(i, 1) - b * neg(i, 2))));
        end
        prob_mat(j, k) = prob;
    end
end
pcolor(transpose(prob_mat));
shading(&amp;#39;interp&amp;#39;);
set(gca, &amp;#39;XTick&amp;#39;, [], &amp;#39;YTick&amp;#39;, []);

% draw samples from posterior by rejection sampling
for j = 1:1000
    a = -3 + rand()*6;
    b = -3 + rand()*6;
    prob = normpdf(a, mu, sigma) * normpdf(b, mu, sigma);
    for i = 1:size(pos, 1)
        prob = prob * 1/(1 + exp(-a * pos(i, 1) - b * pos(i, 2)));
    end
    for i = 1:size(neg, 1)
        prob = prob * (1 - 1/(1 + exp(-a * neg(i, 1) - b * neg(i, 2))));
    end
    u = rand();
    if prob / max(prob_mat(:)) &amp;gt; u
        % accept
        plot(x, -a/b * x, &amp;#39;color&amp;#39;, [0.2 0.2 0.2]);
    else
        % reject
        plot(x, -a/b * x, &amp;#39;color&amp;#39;, [0.8 0.8 0.8]);
    end
    hold on
end
axis([-box box -box box]);

% the mean line
[maxp, I] = max(prob_mat(:));
[maxj, maxk] = ind2sub(size(prob_mat), I);
maxa = x(maxj);
maxb = x(maxk);
plot(x, -maxa/maxb * x, &amp;#39;color&amp;#39;, [1 0 0], &amp;#39;LineWidth&amp;#39;, 2);
hold on

% test data point
test = [1, 0];
norm_prob = prob_mat / sum(prob_mat(:));
p = 0;
for j = 1:length(x)
    for k = 1:length(x)
        a = x(j);
        b = x(k);
        p = p + norm_prob(j, k) * 1/(1 + exp(-a * test(1) - b * test(2)));
    end
end
&lt;/code&gt;&lt;/pre&gt;

    &lt;div class="post-tags"&gt;
      &lt;a href="/tags#Bayesian machine learning-ref"&gt;Bayesian machine learning&lt;/a&gt;
      &lt;a href="/tags#logistic regression-ref"&gt;logistic regression&lt;/a&gt;
      &lt;a href="/tags#rejection sampling-ref"&gt;rejection sampling&lt;/a&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class="comments"&gt;
&lt;div id="disqus_thread"&gt;&lt;/div&gt;
&lt;script&gt;
    var disqus_developer = 1;
    var disqus_shortname = 'charlesgao'; // required: replace example with your forum shortname
    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = 'http://' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
&lt;/script&gt;
&lt;noscript&gt;Please enable JavaScript to view the &lt;a href="http://disqus.com/?ref_noscript"&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt;
&lt;a href="http://disqus.com" class="dsq-brlink"&gt;blog comments powered by &lt;span class="logo-disqus"&gt;Disqus&lt;/span&gt;&lt;/a&gt;

&lt;/div&gt;
 

    &lt;/div&gt;
    &lt;!-- Google Prettify --&gt;
&lt;script src="http://cdnjs.cloudflare.com/ajax/libs/prettify/188.0.0/prettify.js"&gt;&lt;/script&gt;
&lt;script&gt;
  var pres = document.getElementsByTagName("pre");
  for (var i=0; i &lt; pres.length; ++i) {
    pres[i].className = "prettyprint ";
  }
  prettyPrint();
&lt;/script&gt;
&lt;!-- end Google Prettify --&gt;
&lt;/body&gt;
&lt;/html&gt;
</description>
    </item>
    <item>
      <title>Online Learning</title>
      <link>http://blog.charlesgao.com//2015/04/29/online-learning.html</link>
      <pubDate>2015-04-29</pubDate>
      <description>&lt;!DOCTYPE html&gt;
&lt;html lang="en"&gt;
&lt;head&gt;
  &lt;meta charset="utf-8"&gt;
  &lt;title&gt;Online Learning&lt;/title&gt;
  &lt;link href="/assets/charlesgao/stylesheets/style.css?0.04928175387218203" type="text/css" rel="stylesheet" media="all"&gt;
&lt;link href="/assets/charlesgao/widgets/google_prettify/stylesheets/twitter-bootstrap.css?0.7069450323246584" type="text/css" rel="stylesheet" media="all"&gt;


  &lt;script&gt;
  var _gaq=[['_setAccount','UA-33798309-1'],['_trackPageview']];
  (function(d,t){var g=d.createElement(t),s=d.getElementsByTagName(t)[0];
  g.src=('https:'==location.protocol?'//ssl':'//www')+'.google-analytics.com/ga.js';
  s.parentNode.insertBefore(g,s)}(document,'script'));
&lt;/script&gt;
    &lt;script type='text/x-mathjax-config'&gt;
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [['$','$'], ['\\(','\\)']],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        }
    });
    MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i &lt; all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
    });
    &lt;/script&gt;
    &lt;script type='text/javascript' src='http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'&gt;&lt;/script&gt;
&lt;/head&gt;

&lt;body onLoad="init();"&gt;

    &lt;div class="blog-title"&gt;
      &lt;h1&gt;&lt;a href="/"&gt;Desiderata&lt;/a&gt;&lt;/h1&gt;
      &lt;h3&gt;Yet another blog of Yuan Gao.&lt;/h3&gt;
    &lt;/div&gt;

    &lt;div class="content"&gt;
      &lt;div class="post"&gt;
  &lt;div class="title"&gt;&lt;a href=""&gt;Online Learning&lt;/a&gt; &lt;span class="date"&gt;2015-04-29&lt;/span&gt;&lt;/h3&gt;&lt;/div&gt;
  &lt;div&gt;
  &lt;p&gt;Online learning is an area of machine learning where the data comes in a sequential fashion. This makes the problem particular interesting because it is like playing a game, where you are constantly making decisions as data streams in. The general model of online learning consists of the following steps:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;given current data $x_t$&lt;/li&gt;
&lt;li&gt;perform action $u_t$&lt;/li&gt;
&lt;li&gt;suffer loss $l_t(u_t)$&lt;/li&gt;
&lt;li&gt;set $t = t + 1$, go to 1&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The simple model depicted above turns out to be super powerful and general. Here are some examples:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Online Regression&lt;/strong&gt;. $x_t \in \mathbb{R}^p$ is a data point. $u_t \in \mathbb{R}$ is the prediction. $l_t(u_t) = (u_t - y_t)^2$, where $y_t \in \mathbb{R}$ is the true value. Here we used the square loss, but other loss functions can be used as well, such as absolute loss.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Online Classification&lt;/strong&gt;. $x_t \in \mathbb{R}^p$ is a data point. $u_t \in \{1, 2, \ldots, K\}$ is the prediction. $l_t(u_t) = 1 - \chi\left(u_t = y_t\right)$, where $\chi(\cdot)$ is the indicator function and $y_t \in \{1, 2, \ldots, K\}$ is the true label.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Online Clustering&lt;/strong&gt;.  $x_t \in \mathbb{R}^p$ is a data point. $u_t$ is a partition of the set $\{x_1, x_2, \ldots, x_t\}$. $y_t$ is a human defined optimal partition of the set $\{x_1, x_2, \ldots, x_t\}$. $l_t(u_t)$ is a measure of the difference between these two partitions.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The objective of an online learning model is to minimize the running loss
\begin{equation}
\sum_{t = 1}^T l_t(u_t).
\end{equation}
According to the &lt;em&gt;no free lunch&lt;/em&gt; theorem in machine learning, we have to come up with some hypothesis class to learn the best action sequences $u_t$. Different hypothesis corresponds to different models. Below are some examples:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Online Linear Least Squares&lt;/strong&gt;. $x_t \in \mathbb{R}^p$ is a data point. $u_t \in \mathbb{R}^p$ is the predicted weight vector. $l_t(u_t) = \left(\langle x_t, u_t \rangle - y_t\right)^2$, where $y_t \in \mathbb{R}$ is the true value.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Online Lasso.&lt;/strong&gt; Same as the previous example except that $l_t(u_t) = \left(\langle x_t, u_t \rangle - y_t\right)^2 + ||u_t||_1$. A somewhat equivalent idea is to impose the constraint in the hypothesis class, say let $u_t \in \{ u~| ||u||_1 \le \gamma \}$.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Online Logistic Regression.&lt;/strong&gt; $l_t(u_t) = log(1 + exp(-y_t\langle x_t, u_t \rangle))$, where $y_t \in \{+1, -1\}$ is the true label. &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;After the modelling process, the last thing is to come up with an optimization algorithm to minimize the objective. Unlike offline optimization algorithms where we can evaluate them by studying their convergence properties, in general for online learning an optimal solution does not even exist. For instance, we can take $l_t(u_t) = (-2)^tu_t$. Let the hypothesis class to be $[-1, 1]$, then the optimal solution is -1 for t odd and 1 for t even. Therefore the optimal solution depends on the horizon T. Given a fixed T, there exists an optimal solution from the hypothesis class. It is then natural to define the concept of regret
\begin{equation}
R(T) = \sum_{t = 1}^T l_t(u_t) - \min_{u \in \mathcal{H}}\sum_{t = 1}^T l_t(u),
\end{equation}
where $\mathcal{H}$ is the hypothesis class. The regret basically describes the convergence in optimal value. Similarly, we can also define the regret in optimal solution
\begin{equation}
R_s(T) = \sum_{t=1}^T \lvert u_t - argmin_{u \in \mathcal{H}}\sum_{\tau = 1}^t l_\tau(u) \rvert.
\end{equation}
For loss functions with both strong convexity and smoothness guarantees, $R(T)$ and $R_s(T)$ are equivalent up to a constant. For an online optimization algorithm, we hope that $R(T) = o(T)$. This implies the average regret tends to zero $\lim_{T\rightarrow\infty}R(T)/T = 0$, or on average the online algorithm performs equally well with an offline algorithm. It is unrealistic to ask for $R(T)\rightarrow 0$, because the regret is an accumulated error. &lt;/p&gt;

&lt;h2 id="toc_0"&gt;Convex Loss Functions&lt;/h2&gt;

&lt;p&gt;Throughout the discussion we will stick to convex loss functions, i.e.,  $l_t(\cdot)$ is convex for all $t$. The nice thing about a convex function is that it is bounded below by a line
\begin{equation}
l_t(u_t) - l_t(u) \le \langle z_t, u_t - u \rangle,
\end{equation}
where $z_t \in \partial l_t(u_t)$. In particular, if we choose $u^* = argmin_{u \in \mathcal{H}}\sum_{t = 1}^T l_t(u)$, this implies,
\begin{equation}
R(T) = \sum_{t = 1}^T l_t(u_t) - \sum_{t = 1}^T l_t(u^*) \le \sum_{t = 1}^T \langle z_t, u_t \rangle - \langle z_t, u^* \rangle \le R_L(T),
\end{equation}
where $R_L(T)$ is the regret with respect to the linear loss function $l_t(u_t) = \langle z_t, u_t \rangle$. Therefore we can focus on the regret study of linear loss functions, as they automatically induce an upper bound of the regret of convex loss functions.&lt;/p&gt;

&lt;h2 id="toc_1"&gt;Algorithms&lt;/h2&gt;

&lt;p&gt;A naive algorithm is called &lt;strong&gt;follow-the-leader&lt;/strong&gt;, which is to choose the vector that has the minimum loss on all past rounds.
\begin{equation}
u_t = argmin_{u \in H}\sum_{\tau=1}^{t-1}l_{\tau}(u).
\end{equation}
According to this definition, we have
\begin{equation}
R(T) = \sum_{t = 1}^T l_t(u_t) - \min_{u \in \mathcal{H}}\sum_{t = 1}^T l_t(u) = \sum_{t = 1}^T l_t(u_t) - \sum_{t = 1}^T l_t(u_{T+1}) \le \sum_{t = 1}^T \left(l_t(u_t) - l_t(u_{t+1})\right). 
\end{equation}
Note that here we are&lt;/p&gt;

&lt;p&gt;Contrary to offline optimization where each iteration usually involves going through all the data, one iteration in an online optimization only observes one data. This makes online optimization algorithms preferable even in the offline case when the data size is large.&lt;/p&gt;

&lt;h2 id="toc_2"&gt;Connection to Reinforcement Learning&lt;/h2&gt;

&lt;p&gt;Online learning bears a lot of resemblance to reinforcement learning (RL), in that they both embody the flavor of making decision on the fly. In a typical RL scenario, we have a state space $X$ and any at any state $x \in X$ there is a set of actions $U(x)$ available, so that applying $u \in U(x)$ will lead us to another state $x&amp;#39;$, according to the dynamics $x&amp;#39; = f(x, u)$. At the meantime, we suffer from a loss $l(x, u)$. The goal is to minimize the total cost $\sum_{k=1}^n l(x_k, u_k)$. The infinite horizon formulation usually includes a discount factor $0 &amp;lt; \alpha &amp;lt; 1$ to mimic myopic behavior, so the total cost is $\sum_{k=1}^{\infty} \alpha^kl(x_k, u_k)$. The key factor that distinguishes RL from optimal control theory is that the dynamics $f(x, u)$ (usually modelled as a Markov transition between states $P(x&amp;#39;|x, u)$) and loss function $l(x, u)$ are not known beforehand, something known as partial observability. So a RL model looks like:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;given current state $x_t$&lt;/li&gt;
&lt;li&gt;choose an action $u_t$&lt;/li&gt;
&lt;li&gt;receive $x_{t+1} \sim P(x&amp;#39;|x_t, u_t)$ and $l(x_t, u_t)$&lt;/li&gt;
&lt;li&gt;suffer loss $l(x_t, u_t)$&lt;/li&gt;
&lt;li&gt;set $t = t + 1$, go to 1&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Comparing the model to online learning, we find that RL is actually a special case of online learning where we assume the data $x_{t+1}$ is influenced by our action/prediction at time $t$. Therefore reinforcement learning can be seen as an &lt;em&gt;active&lt;/em&gt; form of learning, where we are using our actions to actively exploring the state space.&lt;/p&gt;

&lt;p&gt;Problem to study:
1. Nesterov&amp;#39;s accerlerated online gradient descent
2. Series Acceleration (Aitken)&lt;/p&gt;

    &lt;div class="post-tags"&gt;
      &lt;a href="/tags#machine learning-ref"&gt;machine learning&lt;/a&gt;
      &lt;a href="/tags#online convex optimization-ref"&gt;online convex optimization&lt;/a&gt;
      &lt;a href="/tags#stochastic optimization-ref"&gt;stochastic optimization&lt;/a&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class="comments"&gt;
&lt;div id="disqus_thread"&gt;&lt;/div&gt;
&lt;script&gt;
    var disqus_developer = 1;
    var disqus_shortname = 'charlesgao'; // required: replace example with your forum shortname
    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = 'http://' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
&lt;/script&gt;
&lt;noscript&gt;Please enable JavaScript to view the &lt;a href="http://disqus.com/?ref_noscript"&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt;
&lt;a href="http://disqus.com" class="dsq-brlink"&gt;blog comments powered by &lt;span class="logo-disqus"&gt;Disqus&lt;/span&gt;&lt;/a&gt;

&lt;/div&gt;
 

    &lt;/div&gt;
    &lt;!-- Google Prettify --&gt;
&lt;script src="http://cdnjs.cloudflare.com/ajax/libs/prettify/188.0.0/prettify.js"&gt;&lt;/script&gt;
&lt;script&gt;
  var pres = document.getElementsByTagName("pre");
  for (var i=0; i &lt; pres.length; ++i) {
    pres[i].className = "prettyprint ";
  }
  prettyPrint();
&lt;/script&gt;
&lt;!-- end Google Prettify --&gt;
&lt;/body&gt;
&lt;/html&gt;
</description>
    </item>
    <item>
      <title>Things About General Exam</title>
      <link>http://blog.charlesgao.com//2014/11/13/things-about-general-exam.html</link>
      <pubDate>2014-11-13</pubDate>
      <description>&lt;!DOCTYPE html&gt;
&lt;html lang="en"&gt;
&lt;head&gt;
  &lt;meta charset="utf-8"&gt;
  &lt;title&gt;Things About General Exam&lt;/title&gt;
  &lt;link href="/assets/charlesgao/stylesheets/style.css?0.13792799825577184" type="text/css" rel="stylesheet" media="all"&gt;
&lt;link href="/assets/charlesgao/widgets/google_prettify/stylesheets/twitter-bootstrap.css?0.27870752776568886" type="text/css" rel="stylesheet" media="all"&gt;


  &lt;script&gt;
  var _gaq=[['_setAccount','UA-33798309-1'],['_trackPageview']];
  (function(d,t){var g=d.createElement(t),s=d.getElementsByTagName(t)[0];
  g.src=('https:'==location.protocol?'//ssl':'//www')+'.google-analytics.com/ga.js';
  s.parentNode.insertBefore(g,s)}(document,'script'));
&lt;/script&gt;
    &lt;script type='text/x-mathjax-config'&gt;
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [['$','$'], ['\\(','\\)']],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        }
    });
    MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i &lt; all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
    });
    &lt;/script&gt;
    &lt;script type='text/javascript' src='http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'&gt;&lt;/script&gt;
&lt;/head&gt;

&lt;body onLoad="init();"&gt;

    &lt;div class="blog-title"&gt;
      &lt;h1&gt;&lt;a href="/"&gt;Desiderata&lt;/a&gt;&lt;/h1&gt;
      &lt;h3&gt;Yet another blog of Yuan Gao.&lt;/h3&gt;
    &lt;/div&gt;

    &lt;div class="content"&gt;
      &lt;div class="post"&gt;
  &lt;div class="title"&gt;&lt;a href=""&gt;Things About General Exam&lt;/a&gt; &lt;span class="date"&gt;2014-11-13&lt;/span&gt;&lt;/h3&gt;&lt;/div&gt;
  &lt;div&gt;
  &lt;p&gt;Today I talked with Professor Mark Kot about my progress in the marathon of PhD. Mark was very helpful and offered me lots of advice. I&amp;#39;m about to take my general exam this year, so it&amp;#39;s important to keep in mind the rules.&lt;/p&gt;

&lt;p&gt;Both the general exam and the final thesis defense are supervised by a committee of four to five professors. Chairman of the committee, of course, is my advisor. One of them is the Graduate School Representative (GPA), and he/she has to be from another department. The main purpose of GPA is to keep my advisor from answering questions for me, thus maintaining the fairness of the exam. Aside from the chairman and GPA, one of the professors must be from the CORE amath faculty. That&amp;#39;s basically all the constraints, so I have the freedom to choose one or two other committee members. And it&amp;#39;s always a good idea to choose professors knowledgeable of the field of my research.&lt;/p&gt;

&lt;p&gt;For the final thesis defense, I have to get my written thesis proofread by the reading committee, which are formed by two members from my supervisory committee, before formally arranging an exam date with the graduate school. One important thing to remind my advisor to bring on the final exam is the warrant, a document that has to be signed by all members.&lt;/p&gt;

    &lt;div class="post-tags"&gt;
      &lt;a href="/tags#graduate school-ref"&gt;graduate school&lt;/a&gt;
      &lt;a href="/tags#general exam-ref"&gt;general exam&lt;/a&gt;
      &lt;a href="/tags#thesis defense-ref"&gt;thesis defense&lt;/a&gt;
      &lt;a href="/tags#applied math-ref"&gt;applied math&lt;/a&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class="comments"&gt;
&lt;div id="disqus_thread"&gt;&lt;/div&gt;
&lt;script&gt;
    var disqus_developer = 1;
    var disqus_shortname = 'charlesgao'; // required: replace example with your forum shortname
    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = 'http://' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
&lt;/script&gt;
&lt;noscript&gt;Please enable JavaScript to view the &lt;a href="http://disqus.com/?ref_noscript"&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt;
&lt;a href="http://disqus.com" class="dsq-brlink"&gt;blog comments powered by &lt;span class="logo-disqus"&gt;Disqus&lt;/span&gt;&lt;/a&gt;

&lt;/div&gt;
 

    &lt;/div&gt;
    &lt;!-- Google Prettify --&gt;
&lt;script src="http://cdnjs.cloudflare.com/ajax/libs/prettify/188.0.0/prettify.js"&gt;&lt;/script&gt;
&lt;script&gt;
  var pres = document.getElementsByTagName("pre");
  for (var i=0; i &lt; pres.length; ++i) {
    pres[i].className = "prettyprint ";
  }
  prettyPrint();
&lt;/script&gt;
&lt;!-- end Google Prettify --&gt;
&lt;/body&gt;
&lt;/html&gt;
</description>
    </item>
    <item>
      <title>Probability Density Function And Partial Differential Equations</title>
      <link>http://blog.charlesgao.com//2014/05/27/probability-density-function-and-partial-differential-equations.html</link>
      <pubDate>2014-05-27</pubDate>
      <description>&lt;!DOCTYPE html&gt;
&lt;html lang="en"&gt;
&lt;head&gt;
  &lt;meta charset="utf-8"&gt;
  &lt;title&gt;Probability Density Function And Partial Differential Equations&lt;/title&gt;
  &lt;link href="/assets/charlesgao/stylesheets/style.css?0.6953629837788103" type="text/css" rel="stylesheet" media="all"&gt;
&lt;link href="/assets/charlesgao/widgets/google_prettify/stylesheets/twitter-bootstrap.css?0.6136436625043067" type="text/css" rel="stylesheet" media="all"&gt;


  &lt;script&gt;
  var _gaq=[['_setAccount','UA-33798309-1'],['_trackPageview']];
  (function(d,t){var g=d.createElement(t),s=d.getElementsByTagName(t)[0];
  g.src=('https:'==location.protocol?'//ssl':'//www')+'.google-analytics.com/ga.js';
  s.parentNode.insertBefore(g,s)}(document,'script'));
&lt;/script&gt;
    &lt;script type='text/x-mathjax-config'&gt;
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [['$','$'], ['\\(','\\)']],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        }
    });
    MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i &lt; all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
    });
    &lt;/script&gt;
    &lt;script type='text/javascript' src='http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'&gt;&lt;/script&gt;
&lt;/head&gt;

&lt;body onLoad="init();"&gt;

    &lt;div class="blog-title"&gt;
      &lt;h1&gt;&lt;a href="/"&gt;Desiderata&lt;/a&gt;&lt;/h1&gt;
      &lt;h3&gt;Yet another blog of Yuan Gao.&lt;/h3&gt;
    &lt;/div&gt;

    &lt;div class="content"&gt;
      &lt;div class="post"&gt;
  &lt;div class="title"&gt;&lt;a href=""&gt;Probability Density Function And Partial Differential Equations&lt;/a&gt; &lt;span class="date"&gt;2014-05-27&lt;/span&gt;&lt;/h3&gt;&lt;/div&gt;
  &lt;div&gt;
  &lt;p&gt;Consider the following problem:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;The price of a stock is described by a Brownian motion. Suppose the starting price is 5, and the company defaults if ever the price drops to zero. What is the probability that the company is bankrupt at time $T$? What is the probability that the price is above 10 at time $T$?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Let&amp;#39;s say the price of the stock is described by the time series $p(t)$. The company is bankrupt at time $T$ if $\exists s \le T$, such that $p(s) = 0$. By the reflection principle of Brownian motion, 
\begin{equation}
P\left(inf_{0\le s\le T}p(s) \le 0\right) = 2P\left(p(T) \le 0\right) = 2\int_{-\infty}^{-5}\frac{1}{\sqrt{2\pi T}}e^{\frac{-x^2}{2T}}.
\end{equation}
For the second question, we need $p(T) &amp;gt; 10$ and $p(s) &amp;gt; 0, \forall 0 \le s \le T$. The probability can be calculated as 
\begin{equation}
P\left(p(T) &amp;gt; 10\right) - P\left(p(T) &amp;gt; 10 \cap inf_{0\le s\le T}p(s) \le 0\right),
\end{equation}
using the fact that $P(A\cap B) = P(A) - P(A\cap B^\complement)$. Note that the latter part is equal to $P\left(p(T) &amp;lt; -10\right)$ (Imagine the price first hits zero, then the probability that it goes back above 10 is equal to a reflecting process that drops below -10). Therefore the probability that the price is above 10 at time $T$ is
\begin{equation}
P\left(p(T) &amp;lt; 0\right) - P\left(p(T) &amp;lt; -10\right) = P\left(-10 \le p(T) &amp;lt; 0\right) = \int_{-15}^{-5}\frac{1}{\sqrt{2\pi T}}e^{\frac{-x^2}{2T}}.
\end{equation}&lt;/p&gt;

&lt;p&gt;Now let&amp;#39;s solve the problem in another way. We know that Brownian motion is governed by the following partial differential equation
\begin{equation}
p_t(x, t) = Dp_{xx}(x, t),
\end{equation}
where $p(x,t)$ is the probability density. For a standard Brownian motion, we have $D = 1/2$. Going back to our problem, we know the stock price satisfies this PDE, with boundary conditions $p(0, t) = 0$ and $p(x, t) \rightarrow 0, x \rightarrow \infty$. The absorbing boundary condition reflects the fact that once the price drops to zero, we are at the point of no return. The initial condition for the density is given by $p(x, 0) = \delta(x - 5)$.&lt;/p&gt;

&lt;p&gt;To solve for this PDE with the above initial and boundary conditions, one always apply the Green function and the method of images. That is, we imagine another point source that is outside of the domain (at $x = -5$) which counteracts the point source at $x = 5$ to give us the boundary condition. The solution is therefore the superposition of two Green functions
\begin{equation}
p(x, t) = G(5) - G(-5) = \frac{1}{\sqrt{2\pi t}}\left(e^{\frac{-(x-5)^2}{2t}} - e^{\frac{-(x+5)^2}{2t}} \right).
\end{equation}
See a plot of this density:&lt;/p&gt;

&lt;p&gt;&lt;img src="/assets/media/fig7.png" /&gt;&lt;/p&gt;

&lt;p&gt;The probability that the company is bankrupt at $T$ is given by
\begin{equation}
1 - \int_0^\infty p(x, T).
\end{equation}
The probability that the price is above 10 at $T$ is given by
\begin{equation}
\int_{10}^\infty p(x, T).
\end{equation}
We can see the close relationship between the method of images and the reflection principle of Brownian motion.&lt;/p&gt;

    &lt;div class="post-tags"&gt;
      &lt;a href="/tags#probability-ref"&gt;probability&lt;/a&gt;
      &lt;a href="/tags#stochastic process-ref"&gt;stochastic process&lt;/a&gt;
      &lt;a href="/tags#brownian motion-ref"&gt;brownian motion&lt;/a&gt;
      &lt;a href="/tags#differential equation-ref"&gt;differential equation&lt;/a&gt;
      &lt;a href="/tags#partial differential equation-ref"&gt;partial differential equation&lt;/a&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class="comments"&gt;
&lt;div id="disqus_thread"&gt;&lt;/div&gt;
&lt;script&gt;
    var disqus_developer = 1;
    var disqus_shortname = 'charlesgao'; // required: replace example with your forum shortname
    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = 'http://' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
&lt;/script&gt;
&lt;noscript&gt;Please enable JavaScript to view the &lt;a href="http://disqus.com/?ref_noscript"&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt;
&lt;a href="http://disqus.com" class="dsq-brlink"&gt;blog comments powered by &lt;span class="logo-disqus"&gt;Disqus&lt;/span&gt;&lt;/a&gt;

&lt;/div&gt;
 

    &lt;/div&gt;
    &lt;!-- Google Prettify --&gt;
&lt;script src="http://cdnjs.cloudflare.com/ajax/libs/prettify/188.0.0/prettify.js"&gt;&lt;/script&gt;
&lt;script&gt;
  var pres = document.getElementsByTagName("pre");
  for (var i=0; i &lt; pres.length; ++i) {
    pres[i].className = "prettyprint ";
  }
  prettyPrint();
&lt;/script&gt;
&lt;!-- end Google Prettify --&gt;
&lt;/body&gt;
&lt;/html&gt;
</description>
    </item>
    <item>
      <title>Conferences Related To Control</title>
      <link>http://blog.charlesgao.com//2013/01/29/conferences-related-to-control.html</link>
      <pubDate>2013-01-29</pubDate>
      <description>&lt;!DOCTYPE html&gt;
&lt;html lang="en"&gt;
&lt;head&gt;
  &lt;meta charset="utf-8"&gt;
  &lt;title&gt;Conferences Related To Control&lt;/title&gt;
  &lt;link href="/assets/charlesgao/stylesheets/style.css?0.43310344412537694" type="text/css" rel="stylesheet" media="all"&gt;
&lt;link href="/assets/charlesgao/widgets/google_prettify/stylesheets/twitter-bootstrap.css?0.590096562396745" type="text/css" rel="stylesheet" media="all"&gt;


  &lt;script&gt;
  var _gaq=[['_setAccount','UA-33798309-1'],['_trackPageview']];
  (function(d,t){var g=d.createElement(t),s=d.getElementsByTagName(t)[0];
  g.src=('https:'==location.protocol?'//ssl':'//www')+'.google-analytics.com/ga.js';
  s.parentNode.insertBefore(g,s)}(document,'script'));
&lt;/script&gt;
    &lt;script type='text/x-mathjax-config'&gt;
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [['$','$'], ['\\(','\\)']],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        }
    });
    MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i &lt; all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
    });
    &lt;/script&gt;
    &lt;script type='text/javascript' src='http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'&gt;&lt;/script&gt;
&lt;/head&gt;

&lt;body onLoad="init();"&gt;

    &lt;div class="blog-title"&gt;
      &lt;h1&gt;&lt;a href="/"&gt;Desiderata&lt;/a&gt;&lt;/h1&gt;
      &lt;h3&gt;Yet another blog of Yuan Gao.&lt;/h3&gt;
    &lt;/div&gt;

    &lt;div class="content"&gt;
      &lt;div class="post"&gt;
  &lt;div class="title"&gt;&lt;a href=""&gt;Conferences Related To Control&lt;/a&gt; &lt;span class="date"&gt;2013-01-29&lt;/span&gt;&lt;/h3&gt;&lt;/div&gt;
  &lt;div&gt;
  &lt;p&gt;&lt;a href="http://dynamicwalking.org"&gt;Dynamic Walking 2013&lt;/a&gt;
Deadline: 2/10/2013&lt;/p&gt;

&lt;p&gt;&lt;a href="http://cdc2013.units.it"&gt;Conference on Decision and Control 2013&lt;/a&gt;
Deadline: 3/4/2013&lt;/p&gt;

&lt;p&gt;&lt;a href="http://www.iros2013.org"&gt;International Conference on Intelligent Robots and Systems 2013&lt;/a&gt;
Deadline: 3/15/2013&lt;/p&gt;

&lt;p&gt;&lt;a href="http://www.wikicfp.com/cfp/servlet/event.showcfp?eventid=21361&amp;amp;copyownerid=1"&gt;Neural Information Processing Systems Conference 2013&lt;/a&gt;
Deadline: 4/15/2013&lt;/p&gt;

&lt;p&gt;&lt;a href="http://www.wikicfp.com/cfp/servlet/event.showcfp?eventid=28382&amp;amp;copyownerid=46723"&gt;IEEE International Conference on Control, Automation, Robotics and Embedded systems&lt;/a&gt;
Deadline: 7/13/2013&lt;/p&gt;

&lt;p&gt;&lt;a href="http://web.utk.edu/%7Ejtan10/icra2014"&gt;International Conference on Robotics and Automation 2014&lt;/a&gt;
Deadline: 8/15/2013&lt;/p&gt;

&lt;p&gt;&lt;a href="http://a2c2.org/conferences/acc2014"&gt;American Control Conference 2014&lt;/a&gt;
Deadline: 9/27/2013&lt;/p&gt;

&lt;p&gt;ADPRL 2014&lt;/p&gt;

    &lt;div class="post-tags"&gt;
      &lt;a href="/tags#conference-ref"&gt;conference&lt;/a&gt;
      &lt;a href="/tags#control-ref"&gt;control&lt;/a&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class="comments"&gt;
&lt;div id="disqus_thread"&gt;&lt;/div&gt;
&lt;script&gt;
    var disqus_developer = 1;
    var disqus_shortname = 'charlesgao'; // required: replace example with your forum shortname
    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = 'http://' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
&lt;/script&gt;
&lt;noscript&gt;Please enable JavaScript to view the &lt;a href="http://disqus.com/?ref_noscript"&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt;
&lt;a href="http://disqus.com" class="dsq-brlink"&gt;blog comments powered by &lt;span class="logo-disqus"&gt;Disqus&lt;/span&gt;&lt;/a&gt;

&lt;/div&gt;
 

    &lt;/div&gt;
    &lt;!-- Google Prettify --&gt;
&lt;script src="http://cdnjs.cloudflare.com/ajax/libs/prettify/188.0.0/prettify.js"&gt;&lt;/script&gt;
&lt;script&gt;
  var pres = document.getElementsByTagName("pre");
  for (var i=0; i &lt; pres.length; ++i) {
    pres[i].className = "prettyprint ";
  }
  prettyPrint();
&lt;/script&gt;
&lt;!-- end Google Prettify --&gt;
&lt;/body&gt;
&lt;/html&gt;
</description>
    </item>
    <item>
      <title>Discovering Prefixes And Suffixes</title>
      <link>http://blog.charlesgao.com//2012/09/25/discovering-prefixes-and-suffixes.html</link>
      <pubDate>2012-09-25</pubDate>
      <description>&lt;!DOCTYPE html&gt;
&lt;html lang="en"&gt;
&lt;head&gt;
  &lt;meta charset="utf-8"&gt;
  &lt;title&gt;Discovering Prefixes And Suffixes&lt;/title&gt;
  &lt;link href="/assets/charlesgao/stylesheets/style.css?0.3689759707545258" type="text/css" rel="stylesheet" media="all"&gt;
&lt;link href="/assets/charlesgao/widgets/google_prettify/stylesheets/twitter-bootstrap.css?0.47265944945830296" type="text/css" rel="stylesheet" media="all"&gt;


  &lt;script&gt;
  var _gaq=[['_setAccount','UA-33798309-1'],['_trackPageview']];
  (function(d,t){var g=d.createElement(t),s=d.getElementsByTagName(t)[0];
  g.src=('https:'==location.protocol?'//ssl':'//www')+'.google-analytics.com/ga.js';
  s.parentNode.insertBefore(g,s)}(document,'script'));
&lt;/script&gt;
    &lt;script type='text/x-mathjax-config'&gt;
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [['$','$'], ['\\(','\\)']],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        }
    });
    MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i &lt; all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
    });
    &lt;/script&gt;
    &lt;script type='text/javascript' src='http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'&gt;&lt;/script&gt;
&lt;/head&gt;

&lt;body onLoad="init();"&gt;

    &lt;div class="blog-title"&gt;
      &lt;h1&gt;&lt;a href="/"&gt;Desiderata&lt;/a&gt;&lt;/h1&gt;
      &lt;h3&gt;Yet another blog of Yuan Gao.&lt;/h3&gt;
    &lt;/div&gt;

    &lt;div class="content"&gt;
      &lt;div class="post"&gt;
  &lt;div class="title"&gt;&lt;a href=""&gt;Discovering Prefixes And Suffixes&lt;/a&gt; &lt;span class="date"&gt;2012-09-25&lt;/span&gt;&lt;/h3&gt;&lt;/div&gt;
  &lt;div&gt;
  &lt;p&gt;English is a language that has a concatinative morphology. For example, the word &lt;em&gt;preinstallation&lt;/em&gt; can be split into three parts -- a prefix &lt;em&gt;pre&lt;/em&gt;, a stem &lt;em&gt;install&lt;/em&gt; and a suffix &lt;em&gt;ation&lt;/em&gt;. Given a corpus of english words, how do we discover the prefixes and suffixes computationally? This is an interesting question, for we can use similar methods to analyze other languages that also share a concatinative morphology.&lt;/p&gt;

&lt;p&gt;The corpus of english words can be represented by a forward tree (and a backward tree). The root of the forward tree is the token that denotes the start of word. Each node in the tree corresponds to a character. A word in the corpus is therefore a path starting from the root. Similarly, for the backward tree, the root is the end of word token. A path starting from the root corresponds to a word reading backwards.&lt;/p&gt;

&lt;p&gt;After building this tree representation, we can calculate the frequency of each node, which is defined as the frequency of the path starting from the root to that node. Since prefixes(or suffixes) tend to appear more often, high frequency candidates are more likely to be considered prefixes(or suffixes) given a fixed character sequence length, or equivalently, a fixed depth in the tree. For instance, for a forward tree, we sort the candidates with tree depth 5 by their frequencies, we get (below the root, i.e. start of word token, is ignored)&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;candidate,frequency&lt;/p&gt;

&lt;p&gt;OVER,378&lt;/p&gt;

&lt;p&gt;INTE,338&lt;/p&gt;

&lt;p&gt;COMP,233&lt;/p&gt;

&lt;p&gt;CONS,212&lt;/p&gt;

&lt;p&gt;UNDE,205&lt;/p&gt;

&lt;p&gt;TRAN,183&lt;/p&gt;

&lt;p&gt;CONT,179&lt;/p&gt;

&lt;p&gt;STRA,150&lt;/p&gt;

&lt;p&gt;COMM,142&lt;/p&gt;

&lt;p&gt;PRES,133&lt;/p&gt;

&lt;p&gt;...&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;It seems that we can capture some prefixes solely by their frequencies. The guy on the top of the list -- &lt;em&gt;OVER&lt;/em&gt; is a common prefix. However, a lot of the high frequency stuff are not actually prefixes, like &lt;em&gt;INTE&lt;/em&gt; and &lt;em&gt;UNDE&lt;/em&gt;. Why do they have a high frequency though? That is because &lt;em&gt;INTER&lt;/em&gt; and &lt;em&gt;UNDER&lt;/em&gt; are prefixes. So high frequency itself is not a sufficient criterion for a prefix.&lt;/p&gt;

&lt;p&gt;It turns out we can eliminate the bad ones by the distribution of their children. For all the characters following &lt;em&gt;INTE&lt;/em&gt;, most of their occurancies should be &lt;em&gt;R&lt;/em&gt;, therefore the distribution of the children of &lt;em&gt;INTE&lt;/em&gt; should be highly biased. A measure that people usually use to discribe this is called &lt;strong&gt;Entropy&lt;/strong&gt;. It is defined as $-\sum_ip_i \ln p_i$, where $p_i$ is the probability of the i-th child. A high entropy implies the children are evenly distributed. Candidate with a high entropy is evidence for a good cut between prefix and stem. That is because varies stems can be attached to the same prefix, so the character following the prefix is rather chaotic.&lt;/p&gt;

&lt;p&gt;It turns out there exist some cases where the boundary of a prefix or suffix does not have a high entropy. The suffix &lt;em&gt;-ing&lt;/em&gt; is a good example. Unfortunately, &lt;em&gt;ling&lt;/em&gt; appears more often than other &lt;em&gt;-ing&lt;/em&gt;&amp;#39;s, like &lt;em&gt;ting&lt;/em&gt; or &lt;em&gt;ming&lt;/em&gt;. Therefore if you look at &lt;em&gt;ing&lt;/em&gt;, it doesn&amp;#39;t have a very high entropy. Combining the frequency and entropy criterions helps a lot, but there are still some corner cases.&lt;/p&gt;

&lt;p&gt;What if we print the frequency and entropy path of each candidate? Below we selected the depth-6 candidates that have both high frequencies and high entropies. We print the frequency and entropy path of each candidate:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;B L A C K 62 2.44667
B L A C   63 0.0815104
B L A 235 2.2194
B L   642 1.52547
B 8561 1.94162&lt;/p&gt;

&lt;p&gt;C R O S S 42 2.58178
C R O S   57 1.11551
C R O 210 2.44689
C R   862 1.68729
C 9225 1.84258&lt;/p&gt;

&lt;p&gt;E X T R A 39 2.25089
E X T R   61 1.11793
E X T 115 1.21067
E X   573 1.98306
E 3922 2.74215&lt;/p&gt;

&lt;p&gt;G R A N D 60 2.69772
G R A N   118 1.94621
G R A 415 2.48571
G R   1114 1.54845
G 5006 2.0093&lt;/p&gt;

&lt;p&gt;G R E E N 72 2.51971
G R E E   94 0.993835
G R E 217 2.10298
G R   1114 1.54845
G 5006 2.0093&lt;/p&gt;

&lt;p&gt;I N T E R 275 2.71212
I N T E   338 0.745482
I N T 439 0.818788
I N   1663 2.41109
I 2849 1.64657&lt;/p&gt;

&lt;p&gt;M I C R O 87 2.63535
M I C R   87 0
M I C 179 1.33012
M I   1377 2.23578
M 8424 1.7602&lt;/p&gt;

&lt;p&gt;M I L L I 41 2.42468
M I L L   87 1.68536
M I L 212 2.2017
M I   1377 2.23578
M 8424 1.7602&lt;/p&gt;

&lt;p&gt;M O N T E 39 2.61507
M O N T   108 2.08311
M O N 330 2.28117
M O   1369 2.53725
M 8424 1.7602&lt;/p&gt;

&lt;p&gt;M U L T I 62 2.37335
M U L T   64 0.160722
M U L 144 1.77535
M U   633 2.32698
M 8424 1.7602&lt;/p&gt;

&lt;p&gt;N O R T H 41 2.251
N O R T   45 0.349945
N O R 185 2.46898
N O   689 2.34442
N 2576 1.62171&lt;/p&gt;

&lt;p&gt;P E T R O 44 2.34169
P E T R   90 1.44709
P E T 189 1.71305
P E   1235 2.18293
P 7159 2.03942&lt;/p&gt;

&lt;p&gt;P H O T O 37 2.30305
P H O T   39 0.202273
P H O 80 1.36333
P H   296 1.71338
P 7159 2.03942&lt;/p&gt;

&lt;p&gt;R O S E N 46 2.41789
R O S E   89 1.74483
R O S 203 1.88389
R O   1140 2.8455
R 6203 1.53285&lt;/p&gt;

&lt;p&gt;S H O R T 40 2.44971
S H O R   56 1.01256
S H O 234 2.55013
S H   1244 1.76214
S 12308 2.54537&lt;/p&gt;

&lt;p&gt;S T O C K 44 2.48733
S T O C   46 0.208982
S T O 288 2.58185
S T   2136 1.75754
S 12308 2.54537&lt;/p&gt;

&lt;p&gt;S U P E R 114 2.60547
S U P E   114 0
S U P 175 0.925686
S U   988 2.47639
S 12308 2.54537&lt;/p&gt;

&lt;p&gt;T R A N S 163 2.53122
T R A N   183 0.565372
T R A 416 2.07768
T R   1053 1.56747
T 4882 2.04851&lt;/p&gt;

&lt;p&gt;U N D E R 187 2.67801
U N D E   205 0.466284
U N D 247 0.711374
U N   1109 2.68328
U 1608 1.33352&lt;/p&gt;

&lt;p&gt;W A T E R 51 2.52729
W A T E   51 0
W A T 99 1.67263
W A   854 2.45031
W 3543 1.7672&lt;/p&gt;

&lt;p&gt;W H I T E 43 2.35619
W H I T   108 2.0792
W H I 196 1.60616
W H   337 1.15808
W 3543 1.7672&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The first number following each candidate is the frequency, and the second is entropy. The feature becomes clear -- a prefix should be one such that its parent has a low entropy and itself has a high entropy. The same applies to suffixes. Now if we look at the entropy path of &lt;em&gt;ing&lt;/em&gt;, we find&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;ING,2.66174&lt;/p&gt;

&lt;p&gt;NG,0.282628&lt;/p&gt;

&lt;p&gt;G,0.646555&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Since &lt;em&gt;NG&lt;/em&gt; has a low entropy and &lt;em&gt;ING&lt;/em&gt; has a high entropy, it becomes clear that &lt;em&gt;ING&lt;/em&gt; should be a suffix.&lt;/p&gt;

&lt;p&gt;The experiment above uses the corpus &lt;a href="http://www.speech.cs.cmu.edu/cgi-bin/cmudict"&gt;CMU Pronouncing Dictionary&lt;/a&gt;. Below is the shell script to generate the frequencies and entropies for the forward and backward tree:
&lt;pre&gt;
#!/bin/sh
#--Generate frequency and entropy for forward&amp;amp;backward tree.--
# == parameters ==
DICT=../data/cmudict.0.7a.txt
ORDER=7
# == function ngramFrequencyEntropy ==
# Generate 1-$2 order grams with frequency and entropy
# $1 : file name
# $2 : order
ngramFrequencyEntropy(){
  CMD=&amp;quot;ngram-count -text $1 -order $2&amp;quot;
  for (( i = 1; i &amp;lt;= $2; i ++ )); do
    CMD=$CMD&amp;quot; -write$i $1.ORDER$i&amp;quot;
  done
  eval $CMD
  for (( i = 1; i &amp;lt;= $2; i ++ )); do
    grep &amp;#39;^&amp;lt;s&amp;gt;&amp;#39; $1.ORDER$i &amp;gt; $1.ORDER$i.PRE
  done&lt;br&gt;
  eval &amp;quot;cat $1.ORDER[1-$(($ORDER-1))].PRE &amp;gt; $3&amp;quot; # cat all the prefixes
  # add the entropy of each node
  LINENUM=1
  AWKCMD=&amp;#39;{sum+=$NF; a[++i]=$NF } END &amp;#39; # simply because its too long...
  AWKCMD+=&amp;#39;{ for(j=1;j&amp;lt;=i;j++) {p = a[j]/sum; entropy += -p*log(p)} } END &amp;#39;
  AWKCMD+=&amp;#39;{print entropy}&amp;#39;
  for (( i = 1; i &amp;lt; $2; i ++ )); do
    while IFS= read -r line; do 
      ENTROPY=&lt;code&gt;echo &amp;quot;$line&amp;quot; | rev | cut -f2- | rev | \
      grep -f- $1.ORDER$(($i+1)).PRE | awk &amp;quot;$AWKCMD&amp;quot;&lt;/code&gt;
      if [ &amp;quot;x$ENTROPY&amp;quot; = &amp;quot;x&amp;quot; ]; then
        ENTROPY=0
      fi
      awk -v ent=$ENTROPY -v ln=$LINENUM \
      &amp;#39;{if (NR==ln) {print $0, ent} else {print $0}}&amp;#39; $3 &amp;gt; TEMP &amp;amp;&amp;amp; mv TEMP $3
      LINENUM=$(($LINENUM+1))
    done &amp;lt; $1.ORDER$i.PRE
  done 
}
# == Generate phoneme and grapheme suffix and prefix trees ==
echo &amp;#39;Generating grapheme trees ...&amp;#39;
sed &amp;#39;/\;\;\;/d;s/  .*//g;/[^A-Za-z]/d&amp;#39; $DICT | \
uniq | sed &amp;#39;s/./ &amp;amp;/g;s/^ //&amp;#39; &amp;gt; CH # char-only
ngramFrequencyEntropy CH $ORDER ch.order$ORDER
rev CH &amp;gt; CH_REV
ngramFrequencyEntropy CH_REV $ORDER ch_rev.order$ORDER
echo &amp;#39;Generating phoneme trees ...&amp;#39;
sed &amp;#39;/\;\;\;/d;s/.*  //g&amp;#39; $DICT &amp;gt; PH # phone-only
ngramFrequencyEntropy PH $ORDER ph.order$ORDER
rev PH &amp;gt; PH_REV
ngramFrequencyEntropy PH_REV $ORDER ph_rev.order$ORDER
# == Remove temp files ==
rm CH CH&lt;em&gt;REV PH PH&lt;/em&gt;REV *ORDER*
&lt;/pre&gt;
Below is the code that generates possible candidates for prefixes and suffixes by selecting those that have both high frequencies and high entropies:
&lt;pre&gt;
#!/bin/sh
# -- generate the candidates using frequency and entropy --
# == parameters ==
ORDER=7
FREQ_CUTOFF=50
ENTR_CUTOFF=50
topFreqEntr(){
  for (( i = 3; i &amp;lt; $2; i ++ )); do
    cat $1.order$i | sort -k$((i+1)) -r -n | head -$FREQ_CUTOFF &amp;gt; topfreq
    cat $1.order$i | sort -k$((i+2)) -r -n | head -$ENTR_CUTOFF &amp;gt; topentr
    sort -o topfreq topfreq
    sort -o topentr topentr
    comm -12 topfreq topentr | sed &amp;quot;s/^\t//g&amp;quot; &amp;gt; $1.order$i.candidates
  done
}
topFreqEntr ch $ORDER
topFreqEntr ph $ORDER
topFreqEntr ch_rev $ORDER
topFreqEntr ph_rev $ORDER
# == clear junk files == 
rm topfreq topentr
&lt;/pre&gt;
Below is the code that prints the frequency and entropy path of candidates:
&lt;pre&gt;
#!/bin/sh
# -- print the path of the candidates --
# == parameters ==
ORDER=7
printPath(){
  while read line; do
    NUM&lt;em&gt;COL=&lt;code&gt;expr $2 - 1&lt;/code&gt;
    echo $line
    while [ $NUM&lt;/em&gt;COL -ge 2 ]; do
      echo $line | cut -d&amp;#39; &amp;#39; -f 1-$NUM_COL | grep -f- $1.order$NUM_COL
      NUM_COL=&lt;code&gt;expr $NUM\_COL - 1&lt;/code&gt;
    done
    echo &amp;quot;&amp;quot;
  done &amp;lt; $1.order$2.candidates
}
for (( i = 3; i &amp;lt; $ORDER; i++ )); do
  printPath ch $i &amp;gt; ch.order$i.candidates.path
  printPath ph $i &amp;gt; ph.order$i.candidates.path
  printPath ch_rev $i &amp;gt; ch_rev.order$i.candidates.path
  printPath ph_rev $i &amp;gt; ph_rev.order$i.candidates.path
done
&lt;/pre&gt;&lt;/p&gt;

    &lt;div class="post-tags"&gt;
      &lt;a href="/tags#language-ref"&gt;language&lt;/a&gt;
      &lt;a href="/tags#text processing-ref"&gt;text processing&lt;/a&gt;
      &lt;a href="/tags#morphology-ref"&gt;morphology&lt;/a&gt;
      &lt;a href="/tags#coding-ref"&gt;coding&lt;/a&gt;
      &lt;a href="/tags#unix-ref"&gt;unix&lt;/a&gt;
      &lt;a href="/tags#shell script-ref"&gt;shell script&lt;/a&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class="comments"&gt;
&lt;div id="disqus_thread"&gt;&lt;/div&gt;
&lt;script&gt;
    var disqus_developer = 1;
    var disqus_shortname = 'charlesgao'; // required: replace example with your forum shortname
    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = 'http://' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
&lt;/script&gt;
&lt;noscript&gt;Please enable JavaScript to view the &lt;a href="http://disqus.com/?ref_noscript"&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt;
&lt;a href="http://disqus.com" class="dsq-brlink"&gt;blog comments powered by &lt;span class="logo-disqus"&gt;Disqus&lt;/span&gt;&lt;/a&gt;

&lt;/div&gt;
 

    &lt;/div&gt;
    &lt;!-- Google Prettify --&gt;
&lt;script src="http://cdnjs.cloudflare.com/ajax/libs/prettify/188.0.0/prettify.js"&gt;&lt;/script&gt;
&lt;script&gt;
  var pres = document.getElementsByTagName("pre");
  for (var i=0; i &lt; pres.length; ++i) {
    pres[i].className = "prettyprint ";
  }
  prettyPrint();
&lt;/script&gt;
&lt;!-- end Google Prettify --&gt;
&lt;/body&gt;
&lt;/html&gt;
</description>
    </item>
    <item>
      <title>Practice Qual Summer 2010 Day1 P4</title>
      <link>http://blog.charlesgao.com//2012/09/06/practice-qual-summer-2010-day1-p4.html</link>
      <pubDate>2012-09-06</pubDate>
      <description>&lt;!DOCTYPE html&gt;
&lt;html lang="en"&gt;
&lt;head&gt;
  &lt;meta charset="utf-8"&gt;
  &lt;title&gt;Practice Qual Summer 2010 Day1 P4&lt;/title&gt;
  &lt;link href="/assets/charlesgao/stylesheets/style.css?0.10672236554625791" type="text/css" rel="stylesheet" media="all"&gt;
&lt;link href="/assets/charlesgao/widgets/google_prettify/stylesheets/twitter-bootstrap.css?0.18141369984039302" type="text/css" rel="stylesheet" media="all"&gt;


  &lt;script&gt;
  var _gaq=[['_setAccount','UA-33798309-1'],['_trackPageview']];
  (function(d,t){var g=d.createElement(t),s=d.getElementsByTagName(t)[0];
  g.src=('https:'==location.protocol?'//ssl':'//www')+'.google-analytics.com/ga.js';
  s.parentNode.insertBefore(g,s)}(document,'script'));
&lt;/script&gt;
    &lt;script type='text/x-mathjax-config'&gt;
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [['$','$'], ['\\(','\\)']],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        }
    });
    MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i &lt; all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
    });
    &lt;/script&gt;
    &lt;script type='text/javascript' src='http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'&gt;&lt;/script&gt;
&lt;/head&gt;

&lt;body onLoad="init();"&gt;

    &lt;div class="blog-title"&gt;
      &lt;h1&gt;&lt;a href="/"&gt;Desiderata&lt;/a&gt;&lt;/h1&gt;
      &lt;h3&gt;Yet another blog of Yuan Gao.&lt;/h3&gt;
    &lt;/div&gt;

    &lt;div class="content"&gt;
      &lt;div class="post"&gt;
  &lt;div class="title"&gt;&lt;a href=""&gt;Practice Qual Summer 2010 Day1 P4&lt;/a&gt; &lt;span class="date"&gt;2012-09-06&lt;/span&gt;&lt;/h3&gt;&lt;/div&gt;
  &lt;div&gt;
  &lt;blockquote&gt;
&lt;p&gt;Assume that $k:[0,1]\times[0,1] \rightarrow \mathcal{R}$ is continuously differentiable and that $f:[0,1] \rightarrow \mathcal{R}$is continuous. Using the definition of the derivative, and the derivative with respect to $x$ of
\begin{equation}
F(x) = \int_0^x k(x,y)f(y)dy, x \in (0,1),
\end{equation}
As an example, let $k(x,y) = x^2y$ and $f(x)=x$. Calculate $F&amp;#39;(x)$ in two different ways: (i) using the formula you found, and (ii) by calculating $F(x)$ and taking a derivative.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;By the definition of derivative,
\begin{equation}
F&amp;#39;(x) = \lim_{\epsilon\rightarrow 0}\frac{F(x+\epsilon)-F(x)}{\epsilon} = \left(\int_0^{x+\epsilon}k(x+\epsilon,y)f(y)dy - \int_0^x k(x,y)f(y)dy\right)/\epsilon
\end{equation}
\begin{equation}
=\lim_{\epsilon\rightarrow 0}\left(\int_0^{x+\epsilon}k(x+\epsilon,y)f(y)dy - \int_0^{x+\epsilon}k(x,y)f(y)dy + \int_0^{x+\epsilon}k(x,y)f(y)dy - \int_0^x k(x,y)f(y)dy\right)/\epsilon
\end{equation}
\begin{equation}
=\lim_{\epsilon\rightarrow 0}\left(\int_0^{x+\epsilon}\frac{k(x+\epsilon,y)-k(x,y)}{\epsilon} f(y)dy  + \frac{1}{\epsilon}\int_x^{x+\epsilon}k(x,y)f(y)dy \right) = \int_0^xk_x(x,y)f(y)dy + k(x,x)f(x)
\end{equation}
In the derivation above, we used the continuously differentiability of $k$ and the continuity of $f$ in exchanging the integral and limit at the second last step.&lt;/p&gt;

&lt;p&gt;For the example $k(x,y)=x^2y$ and $f(x)=x$, we first use our formula:
\begin{equation}
\int_0^xk_x(x,y)f(y)dy + k(x,x)f(x) = \int_0^x2xy^2dy + x^4 = \frac{5}{3}x^4.
\end{equation}
If we calculate it directly, we get
\begin{equation}
\int_0^xk(x,y)f(y)dy = \int_0^xx^2y^2dy = \frac{1}{3}x^5. 
\end{equation}
Then by taking the derivative of $\frac{1}{3}x^5$ respect to $x$ we get the same solution.&lt;/p&gt;

    &lt;div class="post-tags"&gt;
      &lt;a href="/tags#quals-ref"&gt;quals&lt;/a&gt;
      &lt;a href="/tags#analysis-ref"&gt;analysis&lt;/a&gt;
      &lt;a href="/tags#kernel-ref"&gt;kernel&lt;/a&gt;
      &lt;a href="/tags#partial differentiation-ref"&gt;partial differentiation&lt;/a&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class="comments"&gt;
&lt;div id="disqus_thread"&gt;&lt;/div&gt;
&lt;script&gt;
    var disqus_developer = 1;
    var disqus_shortname = 'charlesgao'; // required: replace example with your forum shortname
    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = 'http://' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
&lt;/script&gt;
&lt;noscript&gt;Please enable JavaScript to view the &lt;a href="http://disqus.com/?ref_noscript"&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt;
&lt;a href="http://disqus.com" class="dsq-brlink"&gt;blog comments powered by &lt;span class="logo-disqus"&gt;Disqus&lt;/span&gt;&lt;/a&gt;

&lt;/div&gt;
 

    &lt;/div&gt;
    &lt;!-- Google Prettify --&gt;
&lt;script src="http://cdnjs.cloudflare.com/ajax/libs/prettify/188.0.0/prettify.js"&gt;&lt;/script&gt;
&lt;script&gt;
  var pres = document.getElementsByTagName("pre");
  for (var i=0; i &lt; pres.length; ++i) {
    pres[i].className = "prettyprint ";
  }
  prettyPrint();
&lt;/script&gt;
&lt;!-- end Google Prettify --&gt;
&lt;/body&gt;
&lt;/html&gt;
</description>
    </item>
    <item>
      <title>Practice Qual Summer 2010 Day1 P2</title>
      <link>http://blog.charlesgao.com//2012/09/02/practice-qual-summer-2010-day1-p2.html</link>
      <pubDate>2012-09-02</pubDate>
      <description>&lt;!DOCTYPE html&gt;
&lt;html lang="en"&gt;
&lt;head&gt;
  &lt;meta charset="utf-8"&gt;
  &lt;title&gt;Practice Qual Summer 2010 Day1 P2&lt;/title&gt;
  &lt;link href="/assets/charlesgao/stylesheets/style.css?0.6291591491641836" type="text/css" rel="stylesheet" media="all"&gt;
&lt;link href="/assets/charlesgao/widgets/google_prettify/stylesheets/twitter-bootstrap.css?0.5011279356091936" type="text/css" rel="stylesheet" media="all"&gt;


  &lt;script&gt;
  var _gaq=[['_setAccount','UA-33798309-1'],['_trackPageview']];
  (function(d,t){var g=d.createElement(t),s=d.getElementsByTagName(t)[0];
  g.src=('https:'==location.protocol?'//ssl':'//www')+'.google-analytics.com/ga.js';
  s.parentNode.insertBefore(g,s)}(document,'script'));
&lt;/script&gt;
    &lt;script type='text/x-mathjax-config'&gt;
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [['$','$'], ['\\(','\\)']],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        }
    });
    MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i &lt; all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
    });
    &lt;/script&gt;
    &lt;script type='text/javascript' src='http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'&gt;&lt;/script&gt;
&lt;/head&gt;

&lt;body onLoad="init();"&gt;

    &lt;div class="blog-title"&gt;
      &lt;h1&gt;&lt;a href="/"&gt;Desiderata&lt;/a&gt;&lt;/h1&gt;
      &lt;h3&gt;Yet another blog of Yuan Gao.&lt;/h3&gt;
    &lt;/div&gt;

    &lt;div class="content"&gt;
      &lt;div class="post"&gt;
  &lt;div class="title"&gt;&lt;a href=""&gt;Practice Qual Summer 2010 Day1 P2&lt;/a&gt; &lt;span class="date"&gt;2012-09-02&lt;/span&gt;&lt;/h3&gt;&lt;/div&gt;
  &lt;div&gt;
  &lt;blockquote&gt;
&lt;p&gt;Define the inner product of two functions $f(x)$ and $g(x)$ defined on the interval [0,1] by
\begin{equation}
\langle f,g \rangle = \int_0^1 f(x)g(x)dx
\end{equation}
We say $f$ and $g$ are orthogonal if $\langle f,g \rangle = 0$.
Let $\mathcal{P}$ be the space of cubic polynomials $p(x)$ satisfying $p(1)=p&amp;#39;(1)=0$. This is a two-dimensional linear function space. Determine an orthogonal basis for this space with respect to the inner product above. Note: Orthogonal is enough, it need not be orthonormal.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;First we find two vectors in the space and then we use Gram-Schmidt process to orthogonalize them. &lt;/p&gt;

&lt;p&gt;The general way of finding the two vectors are to assume its form $p(x)=ax^3+bx^2+cx+d$. The two conditions $p(1)=p&amp;#39;(1)=0$ gives us two constrains so that only two variables among $a,b,c$ and $d$ are flexible. That is also the reason why the space is two dimensional. We have
\begin{equation}
\cases{
    a + b + c + d = 0\cr
    3a + 2b + c = 0
}
\end{equation}
We find two linear independent solutions
\begin{equation}
\cases{
    p_1(x) = x^3 - 2x^2 + x\cr
    p_2(x) = 2x^3 - 3x^2 + 1
}
\end{equation}
There are other ways to come up with the two vectors. For example, by observation $x-1$ is also in the space.&lt;/p&gt;

&lt;p&gt;Anyway, we will project $p_2(x)$ onto $p_1(x)$ and then substract that part from $p_2(x)$ to get a vector that is still in the space and is orthogonal to $p_1(x)$. This is done by
\begin{equation}
p_3(x) = p_2(x) - \frac{\langle p_1(x),p_2(x)\rangle}{\langle p_1(x), p_1(x)\rangle}p_1(x) = -\frac{7}{2}x^3+8x^2+1-\frac{11}{2}x
\end{equation}
One can verify that $\langle p_1(x), p_3(x) \rangle = 0$.&lt;/p&gt;

&lt;p&gt;Note: Denote the angle between $p_1(x)$ and $p_2(x)$ as $\theta$. Then $|p_2|cos\theta\vec{e}$ is the projection of $p_2(x)$ onto $p_1(x)$, where $\vec{e}$ is the unit vector with the same direction as $p_1(x)$. 
\begin{equation}
\frac{\langle p_1(x),p_2(x)\rangle}{\langle p_1(x), p_1(x)\rangle}p_1(x) = \frac{|p_1||p_2|cos\theta}{|p_1|^2}p_1 = |p_2|cos\theta\vec{e}
\end{equation}&lt;/p&gt;

    &lt;div class="post-tags"&gt;
      &lt;a href="/tags#quals-ref"&gt;quals&lt;/a&gt;
      &lt;a href="/tags#Gram-Schmidt process-ref"&gt;Gram-Schmidt process&lt;/a&gt;
      &lt;a href="/tags#vector space-ref"&gt;vector space&lt;/a&gt;
      &lt;a href="/tags#orthogonal-ref"&gt;orthogonal&lt;/a&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class="comments"&gt;
&lt;div id="disqus_thread"&gt;&lt;/div&gt;
&lt;script&gt;
    var disqus_developer = 1;
    var disqus_shortname = 'charlesgao'; // required: replace example with your forum shortname
    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = 'http://' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
&lt;/script&gt;
&lt;noscript&gt;Please enable JavaScript to view the &lt;a href="http://disqus.com/?ref_noscript"&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt;
&lt;a href="http://disqus.com" class="dsq-brlink"&gt;blog comments powered by &lt;span class="logo-disqus"&gt;Disqus&lt;/span&gt;&lt;/a&gt;

&lt;/div&gt;
 

    &lt;/div&gt;
    &lt;!-- Google Prettify --&gt;
&lt;script src="http://cdnjs.cloudflare.com/ajax/libs/prettify/188.0.0/prettify.js"&gt;&lt;/script&gt;
&lt;script&gt;
  var pres = document.getElementsByTagName("pre");
  for (var i=0; i &lt; pres.length; ++i) {
    pres[i].className = "prettyprint ";
  }
  prettyPrint();
&lt;/script&gt;
&lt;!-- end Google Prettify --&gt;
&lt;/body&gt;
&lt;/html&gt;
</description>
    </item>
    <item>
      <title>Practice Qual Summer 2010 Day1 P3</title>
      <link>http://blog.charlesgao.com//2012/08/30/practice-qual-summer-2010-day1-p3.html</link>
      <pubDate>2012-08-30</pubDate>
      <description>&lt;!DOCTYPE html&gt;
&lt;html lang="en"&gt;
&lt;head&gt;
  &lt;meta charset="utf-8"&gt;
  &lt;title&gt;Practice Qual Summer 2010 Day1 P3&lt;/title&gt;
  &lt;link href="/assets/charlesgao/stylesheets/style.css?0.8730134791762216" type="text/css" rel="stylesheet" media="all"&gt;
&lt;link href="/assets/charlesgao/widgets/google_prettify/stylesheets/twitter-bootstrap.css?0.11827495181505865" type="text/css" rel="stylesheet" media="all"&gt;


  &lt;script&gt;
  var _gaq=[['_setAccount','UA-33798309-1'],['_trackPageview']];
  (function(d,t){var g=d.createElement(t),s=d.getElementsByTagName(t)[0];
  g.src=('https:'==location.protocol?'//ssl':'//www')+'.google-analytics.com/ga.js';
  s.parentNode.insertBefore(g,s)}(document,'script'));
&lt;/script&gt;
    &lt;script type='text/x-mathjax-config'&gt;
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [['$','$'], ['\\(','\\)']],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        }
    });
    MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i &lt; all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
    });
    &lt;/script&gt;
    &lt;script type='text/javascript' src='http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'&gt;&lt;/script&gt;
&lt;/head&gt;

&lt;body onLoad="init();"&gt;

    &lt;div class="blog-title"&gt;
      &lt;h1&gt;&lt;a href="/"&gt;Desiderata&lt;/a&gt;&lt;/h1&gt;
      &lt;h3&gt;Yet another blog of Yuan Gao.&lt;/h3&gt;
    &lt;/div&gt;

    &lt;div class="content"&gt;
      &lt;div class="post"&gt;
  &lt;div class="title"&gt;&lt;a href=""&gt;Practice Qual Summer 2010 Day1 P3&lt;/a&gt; &lt;span class="date"&gt;2012-08-30&lt;/span&gt;&lt;/h3&gt;&lt;/div&gt;
  &lt;div&gt;
  &lt;blockquote&gt;
&lt;p&gt;Consider the ordinary differential equation
\begin{equation}
\frac{dy}{dt} = -100y
\end{equation}
Your unsophisticated friend is using the forward Euler method to solve this equation over the time interval [0, 5]. He observes a discrete approximation to the solution $y(t)$ whose absolute value increases over time. Is this possible? If so, characterize the time step that he is using. Now answer the same question using the backward Euler method.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;For the forward Euler method, we have $y_{n+1} = y_n + hf(t_n)$, where $h$ is the time spacing. In our case it will become $y_{n+1} = y_n + h(-100y_n) = (1-100h)y_n$. To make the absolute value of $y(t)$ increases over time, we have $|y_{n+1}| &amp;gt; |y_n|$, which gives us $1-100h &amp;gt; 1$ or $1-100h &amp;lt; -1$. Since the timestep $h$ is positive, only the latter case is possible. In that case $h &amp;gt; 0.02$.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;For the backward Euler method, we have $y_{n+1} = y_n + hf(t_{n+1})$. In our case it will become $y_{n+1} = y_n + h(-100y_{n+1})$. To make the absolute value of $y(t)$ increases over time, we have $|y_{n+1}| &amp;gt; |y_n|$, which gives us $0 &amp;lt; 1+100h &amp;lt; 1$ or $-1 &amp;lt; 1+100h &amp;lt; 0$. Since the timestep $h$ is positive, neither case is possible. Therefore it is impossible if backward Euler method is used.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Now we make some plots of the forward Euler method. Note that if we set $h = 0.02$, the absolute value of $y(t)$ will remain the same. In fact it will be oscillating because $y_{n+1} = -y_n$. Below is a plot of the case. We initialize $y(0) = 1$.&lt;/p&gt;

&lt;p&gt;&lt;img src="/assets/media/fig1.png" alt=""&gt;&lt;/p&gt;

&lt;p&gt;If we set $h &amp;gt; 0.02$, it will be like&lt;/p&gt;

&lt;p&gt;&lt;img src="/assets/media/fig2.png" alt=""&gt;&lt;/p&gt;

&lt;p&gt;If we set $h$ slightly smaller than $0.02$, it is still not working correctly, but the amplitude of the solution will not increase.&lt;/p&gt;

&lt;p&gt;&lt;img src="/assets/media/fig3.png" alt=""&gt;&lt;/p&gt;

&lt;p&gt;If we set $h$ small enough, we get the correct behavior&lt;/p&gt;

&lt;p&gt;&lt;img src="/assets/media/fig4.png" alt=""&gt;&lt;/p&gt;

    &lt;div class="post-tags"&gt;
      &lt;a href="/tags#quals-ref"&gt;quals&lt;/a&gt;
      &lt;a href="/tags#numerical methods-ref"&gt;numerical methods&lt;/a&gt;
      &lt;a href="/tags#forward Euler-ref"&gt;forward Euler&lt;/a&gt;
      &lt;a href="/tags#backward Euler-ref"&gt;backward Euler&lt;/a&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class="comments"&gt;
&lt;div id="disqus_thread"&gt;&lt;/div&gt;
&lt;script&gt;
    var disqus_developer = 1;
    var disqus_shortname = 'charlesgao'; // required: replace example with your forum shortname
    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = 'http://' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
&lt;/script&gt;
&lt;noscript&gt;Please enable JavaScript to view the &lt;a href="http://disqus.com/?ref_noscript"&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt;
&lt;a href="http://disqus.com" class="dsq-brlink"&gt;blog comments powered by &lt;span class="logo-disqus"&gt;Disqus&lt;/span&gt;&lt;/a&gt;

&lt;/div&gt;
 

    &lt;/div&gt;
    &lt;!-- Google Prettify --&gt;
&lt;script src="http://cdnjs.cloudflare.com/ajax/libs/prettify/188.0.0/prettify.js"&gt;&lt;/script&gt;
&lt;script&gt;
  var pres = document.getElementsByTagName("pre");
  for (var i=0; i &lt; pres.length; ++i) {
    pres[i].className = "prettyprint ";
  }
  prettyPrint();
&lt;/script&gt;
&lt;!-- end Google Prettify --&gt;
&lt;/body&gt;
&lt;/html&gt;
</description>
    </item>
    <item>
      <title>Practice Qual Summer 2010 Day1 P1</title>
      <link>http://blog.charlesgao.com//2012/08/30/practice-qual-summer-2010-day1-p1.html</link>
      <pubDate>2012-08-30</pubDate>
      <description>&lt;!DOCTYPE html&gt;
&lt;html lang="en"&gt;
&lt;head&gt;
  &lt;meta charset="utf-8"&gt;
  &lt;title&gt;Practice Qual Summer 2010 Day1 P1&lt;/title&gt;
  &lt;link href="/assets/charlesgao/stylesheets/style.css?0.0027102072909994668" type="text/css" rel="stylesheet" media="all"&gt;
&lt;link href="/assets/charlesgao/widgets/google_prettify/stylesheets/twitter-bootstrap.css?0.5470243160235039" type="text/css" rel="stylesheet" media="all"&gt;


  &lt;script&gt;
  var _gaq=[['_setAccount','UA-33798309-1'],['_trackPageview']];
  (function(d,t){var g=d.createElement(t),s=d.getElementsByTagName(t)[0];
  g.src=('https:'==location.protocol?'//ssl':'//www')+'.google-analytics.com/ga.js';
  s.parentNode.insertBefore(g,s)}(document,'script'));
&lt;/script&gt;
    &lt;script type='text/x-mathjax-config'&gt;
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [['$','$'], ['\\(','\\)']],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        }
    });
    MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i &lt; all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
    });
    &lt;/script&gt;
    &lt;script type='text/javascript' src='http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'&gt;&lt;/script&gt;
&lt;/head&gt;

&lt;body onLoad="init();"&gt;

    &lt;div class="blog-title"&gt;
      &lt;h1&gt;&lt;a href="/"&gt;Desiderata&lt;/a&gt;&lt;/h1&gt;
      &lt;h3&gt;Yet another blog of Yuan Gao.&lt;/h3&gt;
    &lt;/div&gt;

    &lt;div class="content"&gt;
      &lt;div class="post"&gt;
  &lt;div class="title"&gt;&lt;a href=""&gt;Practice Qual Summer 2010 Day1 P1&lt;/a&gt; &lt;span class="date"&gt;2012-08-30&lt;/span&gt;&lt;/h3&gt;&lt;/div&gt;
  &lt;div&gt;
  &lt;blockquote&gt;
&lt;p&gt;Consider the following nonlinear system:
\begin{equation}
\cases{
    x&amp;#39; = y + x^2y\cr
    y&amp;#39; = -x + 2xy
}
\end{equation}
Find the fixed points of this system. Determine their stability. Assuming that there are no limit cycles, give a sketch of the phase portrait of the nonlinear system (Put this sketch on a separate page, and make it BIG). If you encounter marginal cases for the fixed points, assume that the linearization gives you the correct result.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;By setting $x&amp;#39; = y&amp;#39; = 0$, we get the only possible fixed point $(0, 0)$. The Jacobian of the vector field $(y + x^2y, -x + 2xy)$ is
\begin{equation}
\left(
\begin{matrix}
    2xy &amp;amp; 1 + x^2 \cr
    -1 + 2y &amp;amp; 2x
\end{matrix}
\right)
\end{equation}
At the origin, the Jacobian becomes
\begin{equation}
\left(
\begin{matrix}
    0 &amp;amp; 1\cr
    -1 &amp;amp; 0
\end{matrix}
\right)
\end{equation}
The two eigenvalues of the Jacobian are both purely imaginary. So we cannot say it is stable or unstable. By plotting the vector field around the origin, we can see that it is a center.&lt;/p&gt;

&lt;p&gt;&lt;img src="/assets/media/fig5.png" width=600px height=600px /&gt;&lt;/p&gt;

&lt;p&gt;Note that when $y = 1/2$, $y&amp;#39; = 0$. Therefore if you start with a state with $y \ge 1/2$, you will never be absorbed into the origin. This can be seen if we plot the vector field in a larger domain.&lt;/p&gt;

&lt;p&gt;&lt;img src="/assets/media/fig6.png" width=600px height=600px /&gt;&lt;/p&gt;

    &lt;div class="post-tags"&gt;
      &lt;a href="/tags#quals-ref"&gt;quals&lt;/a&gt;
      &lt;a href="/tags#dynamical system-ref"&gt;dynamical system&lt;/a&gt;
      &lt;a href="/tags#fixed point-ref"&gt;fixed point&lt;/a&gt;
      &lt;a href="/tags#stability-ref"&gt;stability&lt;/a&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class="comments"&gt;
&lt;div id="disqus_thread"&gt;&lt;/div&gt;
&lt;script&gt;
    var disqus_developer = 1;
    var disqus_shortname = 'charlesgao'; // required: replace example with your forum shortname
    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = 'http://' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
&lt;/script&gt;
&lt;noscript&gt;Please enable JavaScript to view the &lt;a href="http://disqus.com/?ref_noscript"&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt;
&lt;a href="http://disqus.com" class="dsq-brlink"&gt;blog comments powered by &lt;span class="logo-disqus"&gt;Disqus&lt;/span&gt;&lt;/a&gt;

&lt;/div&gt;
 

    &lt;/div&gt;
    &lt;!-- Google Prettify --&gt;
&lt;script src="http://cdnjs.cloudflare.com/ajax/libs/prettify/188.0.0/prettify.js"&gt;&lt;/script&gt;
&lt;script&gt;
  var pres = document.getElementsByTagName("pre");
  for (var i=0; i &lt; pres.length; ++i) {
    pres[i].className = "prettyprint ";
  }
  prettyPrint();
&lt;/script&gt;
&lt;!-- end Google Prettify --&gt;
&lt;/body&gt;
&lt;/html&gt;
</description>
    </item>
    <item>
      <title>One Liners For Text Processing</title>
      <link>http://blog.charlesgao.com//2012/08/17/one-liners-for-text-processing.html</link>
      <pubDate>2012-08-17</pubDate>
      <description>&lt;!DOCTYPE html&gt;
&lt;html lang="en"&gt;
&lt;head&gt;
  &lt;meta charset="utf-8"&gt;
  &lt;title&gt;One Liners For Text Processing&lt;/title&gt;
  &lt;link href="/assets/charlesgao/stylesheets/style.css?0.4267412882690188" type="text/css" rel="stylesheet" media="all"&gt;
&lt;link href="/assets/charlesgao/widgets/google_prettify/stylesheets/twitter-bootstrap.css?0.45033079290903344" type="text/css" rel="stylesheet" media="all"&gt;


  &lt;script&gt;
  var _gaq=[['_setAccount','UA-33798309-1'],['_trackPageview']];
  (function(d,t){var g=d.createElement(t),s=d.getElementsByTagName(t)[0];
  g.src=('https:'==location.protocol?'//ssl':'//www')+'.google-analytics.com/ga.js';
  s.parentNode.insertBefore(g,s)}(document,'script'));
&lt;/script&gt;
    &lt;script type='text/x-mathjax-config'&gt;
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [['$','$'], ['\\(','\\)']],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        }
    });
    MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i &lt; all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
    });
    &lt;/script&gt;
    &lt;script type='text/javascript' src='http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'&gt;&lt;/script&gt;
&lt;/head&gt;

&lt;body onLoad="init();"&gt;

    &lt;div class="blog-title"&gt;
      &lt;h1&gt;&lt;a href="/"&gt;Desiderata&lt;/a&gt;&lt;/h1&gt;
      &lt;h3&gt;Yet another blog of Yuan Gao.&lt;/h3&gt;
    &lt;/div&gt;

    &lt;div class="content"&gt;
      &lt;div class="post"&gt;
  &lt;div class="title"&gt;&lt;a href=""&gt;One Liners For Text Processing&lt;/a&gt; &lt;span class="date"&gt;2012-08-17&lt;/span&gt;&lt;/h3&gt;&lt;/div&gt;
  &lt;div&gt;
  &lt;p&gt;I&amp;#39;m currently playing with the &lt;a href="http://www.speech.cs.cmu.edu/cgi-bin/cmudict"&gt;CMU Pronouncing Dictionary&lt;/a&gt;, which is a word-pronunciation dictionary that contains more than 100,000 items. In dealing with the massive amount of data, I&amp;#39;ve learned some text processing techniques which I think is quite useful because these kinds of tasks, i.e. processing data, are frequently encountered, and being efficient in text manipulation will certainly save our lives.&lt;/p&gt;

&lt;p&gt;The first tool is &lt;em&gt;tr&lt;/em&gt;, which can translate some chars into other chars. As far as I know, it does not support regex. For example, below is a segment of the n-gram counts of the phonemes:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&amp;lt;s&amp;gt; T UH SH 1&lt;/p&gt;

&lt;p&gt;&amp;lt;s&amp;gt; T AE    71&lt;/p&gt;

&lt;p&gt;&amp;lt;s&amp;gt; T AE B  8&lt;/p&gt;

&lt;p&gt;&amp;lt;s&amp;gt; T AE N  9&lt;/p&gt;

&lt;p&gt;&amp;lt;s&amp;gt; T AE K  19&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;What if I want to keep only the numbers? The following command should work:&lt;/p&gt;

&lt;pre&gt; tr -cd '[:digit:]\n' &amp;lt; inputfile &lt;/pre&gt;

&lt;p&gt;That means we delete(-d) all the chars except(-c) the numbers([:digit:], which is same as [0-9]) and line break(\n).&lt;/p&gt;

&lt;p&gt;For the the same task we may also use the following &lt;em&gt;perl&lt;/em&gt; command:&lt;/p&gt;

&lt;pre&gt; perl -i -pe 's/[^0-9\n]//g' inputfile &lt;/pre&gt;

&lt;p&gt;The -i argument means in-place edit, so the inputfile will simply be changed. You can write -i.bak to keep a backup, or simply ignore this option and the result will be displayed in the terminal. The -e argument makes perl code to execute on the command line. And the -p ensures the command to be executed per line. In princple, you can write any valid perl command in the quote. That implies, for instance, you can specify the substitution to happen conditionally on those lines that you desire.&lt;/p&gt;

&lt;p&gt;Instead of using perl, we can simply use &lt;em&gt;sed&lt;/em&gt; almost the same way. Sed is especially designed to do substitution, as its name suggests.&lt;/p&gt;

&lt;p&gt;The &lt;em&gt;sort&lt;/em&gt; command can sort the files by lines, with the -n argument for numerical sorting and -r for descending order. The -k option specify which column to sort. Quite convenient.&lt;/p&gt;

&lt;p&gt;Another powerful command is &lt;em&gt;awk&lt;/em&gt;. For example, you can obtain the sum of the first column of all the lines in a file by a one liner:&lt;/p&gt;

&lt;pre&gt; awk '{s+=$1} END {print s}' inputfile &lt;/pre&gt;

&lt;p&gt;Some other command line tools are also very helpful:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;cat: display files (cat filename), set up a sketch (cat &amp;gt;&amp;gt; filename), or concatenate multiple files (cat file1 file2).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;wc: count the lines, words and chars of a file.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;paste: paste multiple files line by line.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Below is a piece of code I wrote this afternoon for exploring phoneme and character feature representation of each word. The program &lt;em&gt;ngram-count&lt;/em&gt; generates all the ngrams based on the training text. Only the CMU dictionary is required as an input, and the code outputs a sparse matrix representation of each word, in terms of phoneme features and character features respectively.&lt;/p&gt;

&lt;pre&gt;
#!/bin/sh
#--Generate phone and char feature representations.--
#Using ngram-count
#Removing unigram features and features below threshold.

# == Generate features(sorted by frequency) ==

# --
echo 'Generating phoneme features ...'

sed '/\;\;\;/d;s/.*  //g' cmudict.0.7a.txt &gt; PH # phone-only

cat PH | ngram-count -text - -order 4 | \
awk 'BEGIN{FS=" "; OFS="|"}{print $NF, $0}' | sort -n -r -t'|' -k1 | \
awk 'int($1) &gt;=10' | cut -d'|' -f2 | rev | cut -f2- | rev | grep ' ' &gt; PH_F

PH_SIZE=`cat PH_F | wc -l | cut -d' ' -f1`
echo "$PH_SIZE phoneme features generated."
# --
echo 'Generating character features ...'

sed '/\;\;\;/d;s/  .*//g;/[^A-Za-z]/d' cmudict.0.7a.txt | uniq | \
sed 's/./ &amp;/g;s/^ //' &gt; CH # char-only

cat CH | ngram-count -text - -order 4 | \
awk 'BEGIN{FS=" "; OFS="|"}{print $NF, $0}' | sort -n -r -t'|' -k1 | \
awk 'int($1) &gt;=10' | cut -d'|' -f2 | rev | cut -f2- | rev | grep ' ' &gt; CH_F

CH_SIZE=`cat CH_F | wc -l | cut -d' ' -f1`
echo "$CH_SIZE character features generated."
# --

# == Get feature representations ==

rm -f ph_sp ch_sp # clear if exists

cat cmudict.0.7a.txt | grep -v '[^A-Za-z0-9 ]' &gt; CHPH # char-phone dict

CNT=1 # loop counter

while IFS= read -r line; do
  # phone
  echo "$line" | sed 's/.*  //g' | ngram-count -text - -order 4 | \
   rev | cut -f2- | rev | grep ' ' &gt; TMP;
  diff --unchanged-group-format=''$CNT' %df 1|' --old-group-format='' \
   --new-group-format='' --changed-group-format='' PH_F TMP | \
   sed 's/|/\n/g' &gt;&gt; ph_sp
  # char
  echo "$line" | sed 's/  .*//g' | sed 's/./ &amp;/g;s/^ //' | \
   ngram-count -text - -order 4 | rev | cut -f2- | rev | grep ' ' &gt; TMP;
  diff --unchanged-group-format=''$CNT' %df 1|' --old-group-format='' \
   --new-group-format='' --changed-group-format='' CH_F TMP | \
   sed 's/|/\n/g' &gt;&gt; ch_sp
  # counter++
  CNT=`expr $CNT + 1`
done &lt; CHPH

# == Remove temp files ==

rm CH CH_F PH PH_F CHPH TMP
&lt;/pre&gt;

    &lt;div class="post-tags"&gt;
      &lt;a href="/tags#one liner-ref"&gt;one liner&lt;/a&gt;
      &lt;a href="/tags#coding-ref"&gt;coding&lt;/a&gt;
      &lt;a href="/tags#unix-ref"&gt;unix&lt;/a&gt;
      &lt;a href="/tags#text processing-ref"&gt;text processing&lt;/a&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class="comments"&gt;
&lt;div id="disqus_thread"&gt;&lt;/div&gt;
&lt;script&gt;
    var disqus_developer = 1;
    var disqus_shortname = 'charlesgao'; // required: replace example with your forum shortname
    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = 'http://' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
&lt;/script&gt;
&lt;noscript&gt;Please enable JavaScript to view the &lt;a href="http://disqus.com/?ref_noscript"&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt;
&lt;a href="http://disqus.com" class="dsq-brlink"&gt;blog comments powered by &lt;span class="logo-disqus"&gt;Disqus&lt;/span&gt;&lt;/a&gt;

&lt;/div&gt;
 

    &lt;/div&gt;
    &lt;!-- Google Prettify --&gt;
&lt;script src="http://cdnjs.cloudflare.com/ajax/libs/prettify/188.0.0/prettify.js"&gt;&lt;/script&gt;
&lt;script&gt;
  var pres = document.getElementsByTagName("pre");
  for (var i=0; i &lt; pres.length; ++i) {
    pres[i].className = "prettyprint ";
  }
  prettyPrint();
&lt;/script&gt;
&lt;!-- end Google Prettify --&gt;
&lt;/body&gt;
&lt;/html&gt;
</description>
    </item>
    <item>
      <title>Keep Going -- Reading the Ph.D. Grind</title>
      <link>http://blog.charlesgao.com//2012/07/31/keep-going-reading-the-ph-d-grind.html</link>
      <pubDate>2012-07-31</pubDate>
      <description>&lt;!DOCTYPE html&gt;
&lt;html lang="en"&gt;
&lt;head&gt;
  &lt;meta charset="utf-8"&gt;
  &lt;title&gt;Keep Going -- Reading the Ph.D. Grind&lt;/title&gt;
  &lt;link href="/assets/charlesgao/stylesheets/style.css?0.8507063396348546" type="text/css" rel="stylesheet" media="all"&gt;
&lt;link href="/assets/charlesgao/widgets/google_prettify/stylesheets/twitter-bootstrap.css?0.16150248663612654" type="text/css" rel="stylesheet" media="all"&gt;


  &lt;script&gt;
  var _gaq=[['_setAccount','UA-33798309-1'],['_trackPageview']];
  (function(d,t){var g=d.createElement(t),s=d.getElementsByTagName(t)[0];
  g.src=('https:'==location.protocol?'//ssl':'//www')+'.google-analytics.com/ga.js';
  s.parentNode.insertBefore(g,s)}(document,'script'));
&lt;/script&gt;
    &lt;script type='text/x-mathjax-config'&gt;
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [['$','$'], ['\\(','\\)']],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        }
    });
    MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i &lt; all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
    });
    &lt;/script&gt;
    &lt;script type='text/javascript' src='http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'&gt;&lt;/script&gt;
&lt;/head&gt;

&lt;body onLoad="init();"&gt;

    &lt;div class="blog-title"&gt;
      &lt;h1&gt;&lt;a href="/"&gt;Desiderata&lt;/a&gt;&lt;/h1&gt;
      &lt;h3&gt;Yet another blog of Yuan Gao.&lt;/h3&gt;
    &lt;/div&gt;

    &lt;div class="content"&gt;
      &lt;div class="post"&gt;
  &lt;div class="title"&gt;&lt;a href=""&gt;Keep Going -- Reading the Ph.D. Grind&lt;/a&gt; &lt;span class="date"&gt;2012-07-31&lt;/span&gt;&lt;/h3&gt;&lt;/div&gt;
  &lt;div&gt;
  &lt;p&gt;&lt;em&gt;The Ph.D. Grind&lt;/em&gt; is a book written by Philip J. Guo, a student who has just finished his six-year graduate life at Stanford. In the book, Philip mainly addresses his research experience chronologically, giving an detailed account of the kinds of research he did and the way through which he achieved his goal. The book is freely available &lt;a href="http://pgbovine.net/PhD-memoir.htm"&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;This book is definitely worth reading, especially for me as a grad student who is about to start his second year. Luckily Philip happens to be a CS student -- a major very close to mine. So there is a lot I can learn from his experience.&lt;/p&gt;

&lt;p&gt;In &lt;em&gt;Year One&lt;/em&gt; Philip introduces the mechanism behind the publication of CS papers:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Before I continue my story, I want to briefly introduce how academic papers are peer-reviewed and published. In computer science, the most prestigious venues for publishing papers are conferences. Note that in many other academic disciplines, journals are the most prestigious venues, and the word &lt;code&gt;conference&lt;/code&gt; means something quite different. The computer science conference publication process works roughly as follows:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Each conference issues a call for papers with a list of topics of interest and a specific submission deadline.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Researchers submit their papers by that deadline. Each conference typically receives 100 to 300 paper submissions, and each paper contains the equivalent of 30 to 40 pages of double-spaced text.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The conference program committee (PC), consisting of around 20 expert researchers, splits up the submitted papers and reviews them. Each paper is reviewed by three to five people, who are either PC members or volunteer external reviewers solicited by PC members. The review process takes about three months.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;After everyone on the PC is done with their reviews, the PC meets and decides which papers to accept and which to reject based on reviewer preferences.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The PC emails all authors to notify them of whether their papers have been accepted or rejected and attaches the written reviews to the notification emails.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Authors of accepted papers attend the conference to give a 30-minute talk on their paper. All accepted papers are then archived online in a digital library.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;A prestigious top-tier conference accepts 8 to 16 percent of submitted papers, and a second-tier conference accepts 20 to 30 percent. Due to these relatively low acceptance rates, it&amp;#39;s not uncommon for a paper to be rejected, revised, and resubmitted several times before being accepted for publication - a process that might take several years. (A paper can be submitted to only one conference at a time.)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Therefore it is extremely competitive to publish a top-tier conference paper. However, there are ways to improve the chance as Philip unveils the following facts:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Since conferences usually accept less than 20 percent of paper submissions, if reviewers get a bad first impression when reading a paper, then they are likely to reject it. Dawson and I were not specialists in the empirical software measurement subfield, so we weren&amp;#39;t able to &lt;code&gt;pitch&lt;/code&gt; our paper submissions in a way that appealed to reviewers&amp;#39; expectations.&lt;/p&gt;

&lt;p&gt;...&lt;/p&gt;

&lt;p&gt;In contrast, my paper submission with Scott and Joel was far more successful because Scott was an insider who had previously published and reviewed many papers in the HCI conference where we submitted our paper. Of course, being an insider didn&amp;#39;t mean that our paper was scrutinized any less rigorously, since that would be unfair. However, Scott could leverage his experience to present our project&amp;#39;s motivations and findings in a way that was the most palatable to those sorts of reviewers, thereby raising our paper&amp;#39;s chances of acceptance.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Thus before submitting a conference paper, it seems important to consult someone who has at least successfully pusblished a paper in that conference. It takes some time to tune the paper in order to satisfy the taste of the reviewers, so better early than late.&lt;/p&gt;

&lt;p&gt;Throughout the memoir, perhaps the most precious thing I learned is the importance of &lt;strong&gt;connection&lt;/strong&gt;. Philip shows strong initiative and always seek advice and oppotunities from his colleagues and professors. The network enables him to gain an intern position at MSR, to find potential users of his software, to speak at Google Tech Talk, to pursue an visit to Harvard, and much more. Therefore building connection and making use of it is a key source to success. Philip also explains how in the epilogue:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;giving talks, chatting with colleagues, asking for and offering help, and expressing gratitude&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;I think what hinders me from creating my connections is the lack of a good habit of consulting others. When encountering problems, I always attempt to solve them by myself, and seldom seek help from others. Asking for advice is of no harm. Instead it creates serendipities and boosts relationships. A very important point to remember.&lt;/p&gt;

&lt;p&gt;In spite of the successful graduation, Philip chose to quit academia and is now working at Google. His strong initiative and good working habits will certainly push himself towards future success. Anyway, thanks for the great book, Philip!&lt;/p&gt;

    &lt;div class="post-tags"&gt;
      &lt;a href="/tags#reading-ref"&gt;reading&lt;/a&gt;
      &lt;a href="/tags#academia-ref"&gt;academia&lt;/a&gt;
      &lt;a href="/tags#research-ref"&gt;research&lt;/a&gt;
      &lt;a href="/tags#connection-ref"&gt;connection&lt;/a&gt;
      &lt;a href="/tags#the Ph.D. Grind-ref"&gt;the Ph.D. Grind&lt;/a&gt;
      &lt;a href="/tags#Philip J. Guo-ref"&gt;Philip J. Guo&lt;/a&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class="comments"&gt;
&lt;div id="disqus_thread"&gt;&lt;/div&gt;
&lt;script&gt;
    var disqus_developer = 1;
    var disqus_shortname = 'charlesgao'; // required: replace example with your forum shortname
    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = 'http://' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
&lt;/script&gt;
&lt;noscript&gt;Please enable JavaScript to view the &lt;a href="http://disqus.com/?ref_noscript"&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt;
&lt;a href="http://disqus.com" class="dsq-brlink"&gt;blog comments powered by &lt;span class="logo-disqus"&gt;Disqus&lt;/span&gt;&lt;/a&gt;

&lt;/div&gt;
 

    &lt;/div&gt;
    &lt;!-- Google Prettify --&gt;
&lt;script src="http://cdnjs.cloudflare.com/ajax/libs/prettify/188.0.0/prettify.js"&gt;&lt;/script&gt;
&lt;script&gt;
  var pres = document.getElementsByTagName("pre");
  for (var i=0; i &lt; pres.length; ++i) {
    pres[i].className = "prettyprint ";
  }
  prettyPrint();
&lt;/script&gt;
&lt;!-- end Google Prettify --&gt;
&lt;/body&gt;
&lt;/html&gt;
</description>
    </item>
  </channel>
</rss>
